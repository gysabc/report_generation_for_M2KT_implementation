<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>

<link href='https://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext' rel='stylesheet' type='text/css' /><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color:#ffffff; --text-color:#333333; --select-text-bg-color:#B5D6FC; --select-text-font-color:auto; --monospace:"Lucida Console",Consolas,"Courier",monospace; --title-bar-height:20px; }
.mac-os-11 { --title-bar-height:28px; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
h1, h2, h3, h4, h5 { white-space: pre-wrap; }
body { margin: 0px; padding: 0px; height: auto; inset: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 36px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
.typora-export .task-list-item input { pointer-events: none; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; image-orientation: from-image; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px; }
thead, tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-fences-adv-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
svg { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li blockquote { margin: 1rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; }
  #write { margin-top: 0px; border-color: transparent !important; padding-top: 0px !important; padding-bottom: 0px !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  .typora-export #write { break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  .is-mac table { break-inside: avoid; }
  #write > p:nth-child(1) { margin-top: 0px; }
  .typora-export-show-outline .typora-export-sidebar { display: none; }
  figure { overflow-x: visible; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
#write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
.MathJax_ref { fill: currentcolor; }
[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.reversefootnote { font-family: ui-monospace, sans-serif; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.6; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }
mark { background: rgb(255, 255, 0); color: rgb(0, 0, 0); }
.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; }
.md-expand mark .md-meta { opacity: 0.3 !important; }
mark .md-meta { color: rgb(0, 0, 0); }
@media print {
  .typora-export h1, .typora-export h2, .typora-export h3, .typora-export h4, .typora-export h5, .typora-export h6 { break-inside: avoid; }
}
.md-diagram-panel .messageText { stroke: none !important; }
.md-diagram-panel .start-state { fill: var(--node-fill); }
.md-diagram-panel .edgeLabel rect { opacity: 1 !important; }
.md-fences.md-fences-math { font-size: 1em; }
.md-fences-advanced:not(.md-focus) { padding: 0px; white-space: nowrap; border: 0px; }
.md-fences-advanced:not(.md-focus) { background: inherit; }
.typora-export-show-outline .typora-export-content { max-width: 1440px; margin: auto; display: flex; flex-direction: row; }
.typora-export-sidebar { width: 300px; font-size: 0.8rem; margin-top: 80px; margin-right: 18px; }
.typora-export-show-outline #write { --webkit-flex:2; flex: 2 1 0%; }
.typora-export-sidebar .outline-content { position: fixed; top: 0px; max-height: 100%; overflow: hidden auto; padding-bottom: 30px; padding-top: 60px; width: 300px; }
@media screen and (max-width: 1024px) {
  .typora-export-sidebar, .typora-export-sidebar .outline-content { width: 240px; }
}
@media screen and (max-width: 800px) {
  .typora-export-sidebar { display: none; }
}
.outline-content li, .outline-content ul { margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px; list-style: none; overflow-wrap: anywhere; }
.outline-content ul { margin-top: 0px; margin-bottom: 0px; }
.outline-content strong { font-weight: 400; }
.outline-expander { width: 1rem; height: 1.42857rem; position: relative; display: table-cell; vertical-align: middle; cursor: pointer; padding-left: 4px; }
.outline-expander::before { content: ""; position: relative; font-family: Ionicons; display: inline-block; font-size: 8px; vertical-align: middle; }
.outline-item { padding-top: 3px; padding-bottom: 3px; cursor: pointer; }
.outline-expander:hover::before { content: ""; }
.outline-h1 > .outline-item { padding-left: 0px; }
.outline-h2 > .outline-item { padding-left: 1em; }
.outline-h3 > .outline-item { padding-left: 2em; }
.outline-h4 > .outline-item { padding-left: 3em; }
.outline-h5 > .outline-item { padding-left: 4em; }
.outline-h6 > .outline-item { padding-left: 5em; }
.outline-label { cursor: pointer; display: table-cell; vertical-align: middle; text-decoration: none; color: inherit; }
.outline-label:hover { text-decoration: underline; }
.outline-item:hover { border-color: rgb(245, 245, 245); background-color: var(--item-hover-bg-color); }
.outline-item:hover { margin-left: -28px; margin-right: -28px; border-left: 28px solid transparent; border-right: 28px solid transparent; }
.outline-item-single .outline-expander::before, .outline-item-single .outline-expander:hover::before { display: none; }
.outline-item-open > .outline-item > .outline-expander::before { content: ""; }
.outline-children { display: none; }
.info-panel-tab-wrapper { display: none; }
.outline-item-open > .outline-children { display: block; }
.typora-export .outline-item { padding-top: 1px; padding-bottom: 1px; }
.typora-export .outline-item:hover { margin-right: -8px; border-right: 8px solid transparent; }
.typora-export .outline-expander::before { content: "+"; font-family: inherit; top: -1px; }
.typora-export .outline-expander:hover::before, .typora-export .outline-item-open > .outline-item > .outline-expander::before { content: "−"; }
.typora-export-collapse-outline .outline-children { display: none; }
.typora-export-collapse-outline .outline-item-open > .outline-children, .typora-export-no-collapse-outline .outline-children { display: block; }
.typora-export-no-collapse-outline .outline-expander::before { content: "" !important; }
.typora-export-show-outline .outline-item-active > .outline-item .outline-label { font-weight: 700; }
.md-inline-math-container mjx-container { zoom: 0.95; }
mjx-container { break-inside: avoid; }


.CodeMirror { height: auto; }
.CodeMirror.cm-s-inner { background: inherit; }
.CodeMirror-scroll { overflow: auto hidden; z-index: 3; }
.CodeMirror-gutter-filler, .CodeMirror-scrollbar-filler { background-color: rgb(255, 255, 255); }
.CodeMirror-gutters { border-right: 1px solid rgb(221, 221, 221); background: inherit; white-space: nowrap; }
.CodeMirror-linenumber { padding: 0px 3px 0px 5px; text-align: right; color: rgb(153, 153, 153); }
.cm-s-inner .cm-keyword { color: rgb(119, 0, 136); }
.cm-s-inner .cm-atom, .cm-s-inner.cm-atom { color: rgb(34, 17, 153); }
.cm-s-inner .cm-number { color: rgb(17, 102, 68); }
.cm-s-inner .cm-def { color: rgb(0, 0, 255); }
.cm-s-inner .cm-variable { color: rgb(0, 0, 0); }
.cm-s-inner .cm-variable-2 { color: rgb(0, 85, 170); }
.cm-s-inner .cm-variable-3 { color: rgb(0, 136, 85); }
.cm-s-inner .cm-string { color: rgb(170, 17, 17); }
.cm-s-inner .cm-property { color: rgb(0, 0, 0); }
.cm-s-inner .cm-operator { color: rgb(152, 26, 26); }
.cm-s-inner .cm-comment, .cm-s-inner.cm-comment { color: rgb(170, 85, 0); }
.cm-s-inner .cm-string-2 { color: rgb(255, 85, 0); }
.cm-s-inner .cm-meta { color: rgb(85, 85, 85); }
.cm-s-inner .cm-qualifier { color: rgb(85, 85, 85); }
.cm-s-inner .cm-builtin { color: rgb(51, 0, 170); }
.cm-s-inner .cm-bracket { color: rgb(153, 153, 119); }
.cm-s-inner .cm-tag { color: rgb(17, 119, 0); }
.cm-s-inner .cm-attribute { color: rgb(0, 0, 204); }
.cm-s-inner .cm-header, .cm-s-inner.cm-header { color: rgb(0, 0, 255); }
.cm-s-inner .cm-quote, .cm-s-inner.cm-quote { color: rgb(0, 153, 0); }
.cm-s-inner .cm-hr, .cm-s-inner.cm-hr { color: rgb(153, 153, 153); }
.cm-s-inner .cm-link, .cm-s-inner.cm-link { color: rgb(0, 0, 204); }
.cm-negative { color: rgb(221, 68, 68); }
.cm-positive { color: rgb(34, 153, 34); }
.cm-header, .cm-strong { font-weight: 700; }
.cm-del { text-decoration: line-through; }
.cm-em { font-style: italic; }
.cm-link { text-decoration: underline; }
.cm-error { color: red; }
.cm-invalidchar { color: red; }
.cm-constant { color: rgb(38, 139, 210); }
.cm-defined { color: rgb(181, 137, 0); }
div.CodeMirror span.CodeMirror-matchingbracket { color: rgb(0, 255, 0); }
div.CodeMirror span.CodeMirror-nonmatchingbracket { color: rgb(255, 34, 34); }
.cm-s-inner .CodeMirror-activeline-background { background: inherit; }
.CodeMirror { position: relative; overflow: hidden; }
.CodeMirror-scroll { height: 100%; outline: 0px; position: relative; box-sizing: content-box; background: inherit; }
.CodeMirror-sizer { position: relative; }
.CodeMirror-gutter-filler, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-vscrollbar { position: absolute; z-index: 6; display: none; outline: 0px; }
.CodeMirror-vscrollbar { right: 0px; top: 0px; overflow: hidden; }
.CodeMirror-hscrollbar { bottom: 0px; left: 0px; overflow: auto hidden; }
.CodeMirror-scrollbar-filler { right: 0px; bottom: 0px; }
.CodeMirror-gutter-filler { left: 0px; bottom: 0px; }
.CodeMirror-gutters { position: absolute; left: 0px; top: 0px; padding-bottom: 10px; z-index: 3; overflow-y: hidden; }
.CodeMirror-gutter { white-space: normal; height: 100%; box-sizing: content-box; padding-bottom: 30px; margin-bottom: -32px; display: inline-block; }
.CodeMirror-gutter-wrapper { position: absolute; z-index: 4; background: 0px 0px !important; border: none !important; }
.CodeMirror-gutter-background { position: absolute; top: 0px; bottom: 0px; z-index: 4; }
.CodeMirror-gutter-elt { position: absolute; cursor: default; z-index: 4; }
.CodeMirror-lines { cursor: text; }
.CodeMirror pre { border-radius: 0px; border-width: 0px; background: 0px 0px; font-family: inherit; font-size: inherit; margin: 0px; white-space: pre; overflow-wrap: normal; color: inherit; z-index: 2; position: relative; overflow: visible; }
.CodeMirror-wrap pre { overflow-wrap: break-word; white-space: pre-wrap; word-break: normal; }
.CodeMirror-code pre { border-right: 30px solid transparent; width: fit-content; }
.CodeMirror-wrap .CodeMirror-code pre { border-right: none; width: auto; }
.CodeMirror-linebackground { position: absolute; inset: 0px; z-index: 0; }
.CodeMirror-linewidget { position: relative; z-index: 2; overflow: auto; }
.CodeMirror-wrap .CodeMirror-scroll { overflow-x: hidden; }
.CodeMirror-measure { position: absolute; width: 100%; height: 0px; overflow: hidden; visibility: hidden; }
.CodeMirror-measure pre { position: static; }
.CodeMirror div.CodeMirror-cursor { position: absolute; visibility: hidden; border-right: none; width: 0px; }
.CodeMirror div.CodeMirror-cursor { visibility: hidden; }
.CodeMirror-focused div.CodeMirror-cursor { visibility: inherit; }
.cm-searching { background: rgba(255, 255, 0, 0.4); }
span.cm-underlined { text-decoration: underline; }
span.cm-strikethrough { text-decoration: line-through; }
.cm-tw-syntaxerror { color: rgb(255, 255, 255); background-color: rgb(153, 0, 0); }
.cm-tw-deleted { text-decoration: line-through; }
.cm-tw-header5 { font-weight: 700; }
.cm-tw-listitem:first-child { padding-left: 10px; }
.cm-tw-box { border-style: solid; border-right-width: 1px; border-bottom-width: 1px; border-left-width: 1px; border-color: inherit; border-top-width: 0px !important; }
.cm-tw-underline { text-decoration: underline; }
@media print {
  .CodeMirror div.CodeMirror-cursor { visibility: hidden; }
}


:root {
    --side-bar-bg-color: #fafafa;
    --control-text-color: #777;
}

@include-when-export url(https://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext);

/* open-sans-regular - latin-ext_latin */
  /* open-sans-italic - latin-ext_latin */
    /* open-sans-700 - latin-ext_latin */
    /* open-sans-700italic - latin-ext_latin */
  html {
    font-size: 16px;
    -webkit-font-smoothing: antialiased;
}

body {
    font-family: "Open Sans","Clear Sans", "Helvetica Neue", Helvetica, Arial, 'Segoe UI Emoji', sans-serif;
    color: rgb(51, 51, 51);
    line-height: 1.6;
}

#write {
    max-width: 860px;
  	margin: 0 auto;
  	padding: 30px;
    padding-bottom: 100px;
}

@media only screen and (min-width: 1400px) {
	#write {
		max-width: 1024px;
	}
}

@media only screen and (min-width: 1800px) {
	#write {
		max-width: 1200px;
	}
}

#write > ul:first-child,
#write > ol:first-child{
    margin-top: 30px;
}

a {
    color: #4183C4;
}
h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 1rem;
    font-weight: bold;
    line-height: 1.4;
    cursor: text;
}
h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}
h1 tt,
h1 code {
    font-size: inherit;
}
h2 tt,
h2 code {
    font-size: inherit;
}
h3 tt,
h3 code {
    font-size: inherit;
}
h4 tt,
h4 code {
    font-size: inherit;
}
h5 tt,
h5 code {
    font-size: inherit;
}
h6 tt,
h6 code {
    font-size: inherit;
}
h1 {
    font-size: 2.25em;
    line-height: 1.2;
    border-bottom: 1px solid #eee;
}
h2 {
    font-size: 1.75em;
    line-height: 1.225;
    border-bottom: 1px solid #eee;
}

/*@media print {
    .typora-export h1,
    .typora-export h2 {
        border-bottom: none;
        padding-bottom: initial;
    }

    .typora-export h1::after,
    .typora-export h2::after {
        content: "";
        display: block;
        height: 100px;
        margin-top: -96px;
        border-top: 1px solid #eee;
    }
}*/

h3 {
    font-size: 1.5em;
    line-height: 1.43;
}
h4 {
    font-size: 1.25em;
}
h5 {
    font-size: 1em;
}
h6 {
   font-size: 1em;
    color: #777;
}
p,
blockquote,
ul,
ol,
dl,
table{
    margin: 0.8em 0;
}
li>ol,
li>ul {
    margin: 0 0;
}
hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

li p.first {
    display: inline-block;
}
ul,
ol {
    padding-left: 30px;
}
ul:first-child,
ol:first-child {
    margin-top: 0;
}
ul:last-child,
ol:last-child {
    margin-bottom: 0;
}
blockquote {
    border-left: 4px solid #dfe2e5;
    padding: 0 15px;
    color: #777777;
}
blockquote blockquote {
    padding-right: 0;
}
table {
    padding: 0;
    word-break: initial;
}
table tr {
    border: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}
table tr:nth-child(2n),
thead {
    background-color: #f8f8f8;
}
table th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    margin: 0;
    padding: 6px 13px;
}
table td {
    border: 1px solid #dfe2e5;
    margin: 0;
    padding: 6px 13px;
}
table th:first-child,
table td:first-child {
    margin-top: 0;
}
table th:last-child,
table td:last-child {
    margin-bottom: 0;
}

.CodeMirror-lines {
    padding-left: 4px;
}

.code-tooltip {
    box-shadow: 0 1px 1px 0 rgba(0,28,36,.3);
    border-top: 1px solid #eef2f2;
}

.md-fences,
code,
tt {
    border: 1px solid #e7eaed;
    background-color: #f8f8f8;
    border-radius: 3px;
    padding: 0;
    padding: 2px 4px 0px 4px;
    font-size: 0.9em;
}

code {
    background-color: #f3f4f4;
    padding: 0 2px 0 2px;
}

.md-fences {
    margin-bottom: 15px;
    margin-top: 15px;
    padding-top: 8px;
    padding-bottom: 6px;
}


.md-task-list-item > input {
  margin-left: -1.3em;
}

@media print {
    html {
        font-size: 13px;
    }
    pre {
        page-break-inside: avoid;
        word-wrap: break-word;
    }
}

.md-fences {
	background-color: #f8f8f8;
}
#write pre.md-meta-block {
	padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block>.code-tooltip {
	bottom: .375rem;
}

.md-mathjax-midline {
    background: #fafafa;
}

#write>h3.md-focus:before{
	left: -1.5625rem;
	top: .375rem;
}
#write>h4.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
#write>h5.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
#write>h6.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
.md-image>.md-meta {
    /*border: 1px solid #ddd;*/
    border-radius: 3px;
    padding: 2px 0px 0px 4px;
    font-size: 0.9em;
    color: inherit;
}

.md-tag {
    color: #a7a7a7;
    opacity: 1;
}

.md-toc { 
    margin-top:20px;
    padding-bottom:20px;
}

.sidebar-tabs {
    border-bottom: none;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

/** focus mode */
.on-focus-mode blockquote {
    border-left-color: rgba(85, 85, 85, 0.12);
}

header, .context-menu, .megamenu-content, footer{
    font-family: "Segoe UI", "Arial", sans-serif;
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state{
    visibility: visible;
}

.mac-seamless-mode #typora-sidebar {
    background-color: #fafafa;
    background-color: var(--side-bar-bg-color);
}

.md-lang {
    color: #b4654d;
}

/*.html-for-mac {
    --item-hover-bg-color: #E6F0FE;
}*/

#md-notification .btn {
    border: 0;
}

.dropdown-menu .divider {
    border-color: #e5e5e5;
    opacity: 0.4;
}

.ty-preferences .window-content {
    background-color: #fafafa;
}

.ty-preferences .nav-group-item.active {
    color: white;
    background: #999;
}

.menu-item-container a.menu-style-btn {
    background-color: #f5f8fa;
    background-image: linear-gradient( 180deg , hsla(0, 0%, 100%, 0.8), hsla(0, 0%, 100%, 0)); 
}



mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG2"] path[data-c], mjx-container[jax="SVG2"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}
mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
							stroke-width: 0;
						}
</style><title>1-report_generation_for_M2KT</title>
</head>
<body class='typora-export os-windows typora-export-show-outline typora-export-no-collapse-outline'><div class='typora-export-content'>
<div class="typora-export-sidebar"><div class="outline-content"><li class="outline-item-wrapper outline-h1"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#1环境准备">1环境准备</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h2"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#11相关包安装的命令">1.1相关包安装的命令</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h1"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#2数据集准备">2数据集准备</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h2"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#21iu数据集下载及解析">2.1IU数据集下载及解析</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h2"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#22使用chexpert抽取标签">2.2使用CheXpert抽取标签</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#221环境准备">2.2.1环境准备</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#222iu数据集报告标签生成">2.2.2IU数据集报告标签生成</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h2"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#23运行配置-在编辑界面模仿命令行调用">2.3运行配置-在编辑界面模仿命令行调用</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h1"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#3模型解析以iu-xray数据集为例">3模型解析(以iu-xray数据集为例)</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h2"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31从mainpy文件出发的">3.1从<code>main.py</code>文件出发的</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#311分词器tokenizer">3.1.1分词器Tokenizer</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#312数据加载器ladataloader">3.1.2数据加载器LADataLoader</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#3121collatefn函数解析">3.1.2.1<code>collate_fn</code>函数解析</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#313创建模型结构">3.1.3创建模型结构</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#3131调用lamrg类的初始化函数">3.1.3.1调用<code>_LAMRG</code>类的初始化函数</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31311visualextractor的创建">3.1.3.1.1<code>visual_extractor</code>的创建</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31312-encoderdecoder的创建">3.1.3.1.2 encoder_decoder的创建</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31313其他">3.1.3.1.3其他</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#3132调用lamrgmodelv9类的初始化函数">3.1.3.2调用<code>LAMRGModel_v9</code>类的初始化函数</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31321textencoder的创建">3.1.3.2.1<code>TextEncoder</code>的创建</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31322memory的创建">3.1.3.2.2<code>memory</code>的创建</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31323其他">3.1.3.2.3其他</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#3133调用lamrgmodelv12类的初始化函数">3.1.3.3调用<code>LAMRGModel_v12</code>类的初始化函数</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31331memory相关的设置">3.1.3.3.1<code>memory</code>相关的设置</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31332线性层的设置">3.1.3.3.2线性层的设置</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31333其他">3.1.3.3.3其他</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#3134模型创建结果">3.1.3.4模型创建结果</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#314创建损失函数和评价矩阵">3.1.4创建损失函数和评价矩阵</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#315构建优化器和学习率调度器">3.1.5构建优化器和学习率调度器</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#3151优化器">3.1.5.1优化器</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#3152调度器">3.1.5.2调度器</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#316构建trainer用于训练管理">3.1.6构建Trainer用于训练管理</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#3161tensorboardx相关知识">3.1.6.1tensorboardX相关知识</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#3162调用basetrainer类的初始化函数">3.1.6.2调用<code>BaseTrainer</code>类的初始化函数</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#3163调用trainer类的初始化函数">3.1.6.3调用<code>Trainer</code>类的初始化函数</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#317开始训练过程">3.1.7开始训练过程</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#3171trainepoch方法的实现过程">3.1.7.1<code>_train_epoch</code>方法的实现过程</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31711数据的读取之getitem方法">3.1.7.1.1数据的读取之getitem方法</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31712数据的处理之collatefn方法">3.1.7.1.2数据的处理之collate_fn方法</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31713lamrgmodelv12模型的前向计算">3.1.7.1.3LAMRGModel_v12模型的前向计算</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h6"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#317131图像特征的提取">3.1.7.1.3.1图像特征的提取</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h6"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#317132特征提取后的处理">3.1.7.1.3.2特征提取后的处理</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h6"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#317133视觉标签的生成">3.1.7.1.3.3视觉标签的生成</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h6"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#317134当前memory的获取">3.1.7.1.3.4当前memory的获取</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h6"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#317135报告文本的编码">3.1.7.1.3.5报告文本的编码</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h6"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#317136对memory进行更新">3.1.7.1.3.6对memory进行更新</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h6"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#317136-visual-knowledge-attention">3.1.7.1.3.6 visual-knowledge attention</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h6"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#317137使用encoderdecoder计算输出">3.1.7.1.3.7使用encoder_decoder计算输出</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h6"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#317138返回前向计算结果">3.1.7.1.3.8返回前向计算结果</a></div><ul class="outline-children"></ul></li></ul></li></ul></li><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#3172train方法的后续内容">3.1.7.2<code>train</code>方法的后续内容</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31721更新最佳结果">3.1.7.2.1更新最佳结果</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31722打印相关信息">3.1.7.2.2打印相关信息</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#31723保存检查点">3.1.7.2.3保存检查点</a></div><ul class="outline-children"></ul></li></ul></li></ul></li></ul></li><li class="outline-item-wrapper outline-h2"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#32分析">3.2分析</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#321关于论文中的标签损失">3.2.1关于论文中的标签损失</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h2"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#33报错信息">3.3报错信息</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#331找不到指定模块">3.3.1找不到指定模块</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#332编码错误">3.3.2编码错误</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#333其他报错信息">3.3.3其他报错信息</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h2"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#4补充">4补充</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h2"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#41损失计算过程">4.1损失计算过程</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#411损失计算">4.1.1损失计算</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#4111计算交叉熵损失">4.1.1.1计算交叉熵损失</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#4112计算标签损失">4.1.1.2计算标签损失</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#4113视觉文本对齐">4.1.1.3视觉文本对齐</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#41131imposterimgloss函数">4.1.1.3.1imposter_img_loss函数</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#41132impostertxtloss函数">4.1.1.3.2imposter_txt_loss函数</a></div><ul class="outline-children"></ul></li><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#41133将两个损失加起来">4.1.1.3.3将两个损失加起来</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#4114整合损失">4.1.1.4整合损失</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#412损失计算结果">4.1.2损失计算结果</a></div><ul class="outline-children"></ul></li></ul></li><li class="outline-item-wrapper outline-h2"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#42当前epoch下对模型进行验证">4.2当前epoch下对模型进行验证</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h3"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#421使用encoderdecoder计算输出">4.2.1使用encoder_decoder计算输出</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h4"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#4211sample方法的具体过程">4.2.1.1_sample方法的具体过程</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h5"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#42111执行attmodel类的samplebeam方法">4.2.1.1.1执行AttModel类的_sample_beam方法</a></div><ul class="outline-children"><li class="outline-item-wrapper outline-h6"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#421111调用getlogprobsstate方法">4.2.1.1.1.1调用<code>get_logprobs_state</code>方法</a></div><ul class="outline-children"></ul></li></ul></li></ul></li></ul></li></ul></li><li class="outline-item-wrapper outline-h2"><div class="outline-item"><span class="outline-expander"></span><a class="outline-label" href="#13当前epoch下对模型进行测试">1.3当前epoch下对模型进行测试</a></div><ul class="outline-children"></ul></li></ul></li></div></div><div id='write'  class=''><p><span>对应的论文地址：</span><a href='https://www.sciencedirect.com/science/article/pii/S1361841523000592'><span>Radiology report generation with a learned knowledge base and multi-modal alignment - ScienceDirect</span></a></p><h1 id='1环境准备'><span>1环境准备</span></h1><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python" style="break-inside: unset;"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><span><span>​</span>x</span></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">## 创建虚拟环境</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">conda</span> <span class="cm-variable">create</span> <span class="cm-operator">-</span><span class="cm-variable">n</span> <span class="cm-variable">report_generation_for_M2KT</span> <span class="cm-variable">pip</span> <span class="cm-variable">python</span><span class="cm-operator">=</span><span class="cm-number">3.6</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">## 激活虚拟环境</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">conda</span> <span class="cm-variable">activate</span> <span class="cm-variable">report_generation_for_M2KT</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">## 安装pytorch</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># CUDA 11.0</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">conda</span> <span class="cm-variable">install</span> <span class="cm-variable">pytorch</span><span class="cm-operator">==</span><span class="cm-number">1.7.0</span> <span class="cm-variable">torchvision</span><span class="cm-operator">==</span><span class="cm-number">0.8.0</span> <span class="cm-variable">torchaudio</span><span class="cm-operator">==</span><span class="cm-number">0.7.0</span> <span class="cm-variable">cudatoolkit</span><span class="cm-operator">=</span><span class="cm-number">11.0</span> <span class="cm-operator">-</span><span class="cm-variable">c</span> <span class="cm-variable">pytorch</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># 更换镜像源</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">conda</span> <span class="cm-variable">install</span> <span class="cm-variable">pytorch</span><span class="cm-operator">==</span><span class="cm-number">1.7.0</span> <span class="cm-variable">torchvision</span><span class="cm-operator">==</span><span class="cm-number">0.8.0</span> <span class="cm-variable">torchaudio</span><span class="cm-operator">==</span><span class="cm-number">0.7.0</span> <span class="cm-variable">cudatoolkit</span><span class="cm-operator">=</span><span class="cm-number">11.0</span> <span class="cm-operator">-</span><span class="cm-variable">c</span> <span class="cm-variable">https</span>:<span class="cm-operator">//</span><span class="cm-variable">mirrors</span>.<span class="cm-property">tuna</span>.<span class="cm-property">tsinghua</span>.<span class="cm-property">edu</span>.<span class="cm-property">cn</span><span class="cm-operator">/</span><span class="cm-variable">anaconda</span><span class="cm-operator">/</span><span class="cm-variable">cloud</span><span class="cm-operator">/</span><span class="cm-variable">pytorch</span><span class="cm-operator">/</span><span class="cm-variable">linux</span><span class="cm-operator">-</span><span class="cm-number">64</span><span class="cm-operator">/</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># 之后根据代码中包的确实情况进行安装，相关缺失的包如下：</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">config</span><span class="cm-operator">/</span><span class="cm-variable">config</span>.<span class="cm-property">py</span>: <span class="cm-variable">yaml、yacs</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># 此外，根据3.3节总结的报错信息，还需要安装以下的包：</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># pandas --直接在对应的代码位置按照提示点击install即可</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">Cython</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">pycocoevalcap</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-operator">--</span><span class="cm-variable">upgrade</span> <span class="cm-variable">pip</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">tensorboardX</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">uninstall</span> <span class="cm-variable">yacs</span> <span class="cm-comment"># 卸载0.1.6</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">yacs</span> <span class="cm-comment"># 默认安装0.1.8版本的</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 484px;"></div><div class="CodeMirror-gutters" style="display: none; height: 484px;"></div></div></div></pre><h2 id='11相关包安装的命令'><span>1.1相关包安装的命令</span></h2><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python" style="break-inside: unset;"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">conda</span> <span class="cm-variable">create</span> <span class="cm-operator">-</span><span class="cm-variable">n</span> <span class="cm-variable">report_generation_for_M2KT</span> <span class="cm-variable">pip</span> <span class="cm-variable">python</span><span class="cm-operator">=</span><span class="cm-number">3.6</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">conda</span> <span class="cm-variable">install</span> <span class="cm-variable">pytorch</span><span class="cm-operator">==</span><span class="cm-number">1.7.0</span> <span class="cm-variable">torchvision</span><span class="cm-operator">==</span><span class="cm-number">0.8.0</span> <span class="cm-variable">torchaudio</span><span class="cm-operator">==</span><span class="cm-number">0.7.0</span> <span class="cm-variable">cudatoolkit</span><span class="cm-operator">=</span><span class="cm-number">11.0</span> <span class="cm-operator">-</span><span class="cm-variable">c</span> <span class="cm-variable">https</span>:<span class="cm-operator">//</span><span class="cm-variable">mirrors</span>.<span class="cm-property">tuna</span>.<span class="cm-property">tsinghua</span>.<span class="cm-property">edu</span>.<span class="cm-property">cn</span><span class="cm-operator">/</span><span class="cm-variable">anaconda</span><span class="cm-operator">/</span><span class="cm-variable">cloud</span><span class="cm-operator">/</span><span class="cm-variable">pytorch</span><span class="cm-operator">/</span><span class="cm-variable">linux</span><span class="cm-operator">-</span><span class="cm-number">64</span><span class="cm-operator">/</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-operator">--</span><span class="cm-variable">upgrade</span> <span class="cm-variable">pip</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">conda</span> <span class="cm-variable">install</span> <span class="cm-variable">yaml</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">Cython</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">pycocoevalcap</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">tensorboardX</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">yacs</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">pandas</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">scipy</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">tqdm</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">ipdb</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 438px;"></div><div class="CodeMirror-gutters" style="display: none; height: 438px;"></div></div></div></pre><p>&nbsp;</p><h1 id='2数据集准备'><span>2数据集准备</span></h1><h2 id='21iu数据集下载及解析'><span>2.1IU数据集下载及解析</span></h2><ol start='' ><li><p><span>官方并没有提供划分好的IU数据集(虽然有</span><a href='https://openi.nlm.nih.gov/faq#collection'><span>下载链接</span></a><span>)，因此这篇论文使用了论文</span><a href='https://github.com/zhjohnchan/R2Gen'><span>R2Gen</span></a><span>中提供的划分好训练集、验证集和测试集的数据</span></p><ol start='' ><li><p><span>与官方提供的IU数据集相比，这个对图像进行了整理，并将报告中的关键信息都整理到了</span><code>annotation.json</code><span>文件中</span></p></li><li><p><span>如下图所示，图片被分类整理，每个文件夹应该是对应于一个病例，其中有几张从不同视角拍摄的肺部放射图像，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230727150423039.png" referrerpolicy="no-referrer" alt="image-20230727150423039"></p></li><li><p><span>总共包含</span><code>6091</code><span>张图片，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230727152120045.png" referrerpolicy="no-referrer" alt="image-20230727152120045"></p></li><li><p><span>在</span><code>annotation.json</code><span>文件中，按照</span><code>7:1:2</code><span>的比例划分了</span><code>train</code><span>、</span><code>val</code><span>、</span><code>test</code><span>，分别包含</span><code>2069</code><span>、</span><code>296</code><span>、</span><code>590</code><span>条数据，共计</span><code>2955</code><span>条数据。</span></p><ol start='' ><li><p><code>2955</code><span>对应于</span><code>images</code><span>文件夹下面的</span><code>2955</code><span>个文件夹，所以可以知道，这</span><code>2955</code><span>个文件夹代表</span><code>2955</code><span>个患者。</span></p></li><li><p><span>因此，这每一条数据对应一个报告，一个报告则对应</span><code>n</code><span>张(</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="5.506ex" height="1.819ex" role="img" focusable="false" viewBox="0 -666 2433.6 804" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.312ex;"><defs><path id="MJX-1-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-N-2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path><path id="MJX-1-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-1-TEX-I-1D45B"></use></g><g data-mml-node="mo" transform="translate(877.8,0)"><use data-c="2265" xlink:href="#MJX-1-TEX-N-2265"></use></g><g data-mml-node="mn" transform="translate(1933.6,0)"><use data-c="32" xlink:href="#MJX-1-TEX-N-32"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≥</mo><mn>2</mn></math></mjx-assistive-mml></mjx-container><script type="math/tex">n\geq2</script><span>)，如下图所示。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230727154551420.png" referrerpolicy="no-referrer" alt="image-20230727154551420"></p></li><li><p><span>每一条数据都包含四个键：</span><code>id</code><span>、</span><code>report</code><span>、</span><code>image_path</code><span>、</span><code>split</code><span>。如下面的两张图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230727154903016.png" referrerpolicy="no-referrer" alt="image-20230727154903016"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230727155705502.png" referrerpolicy="no-referrer" alt="image-20230727155705502"></p></li><li><p><span>因此，annotation文件的格式为：一个大字典，有</span><code>train</code><span>、</span><code>val</code><span>、</span><code>test</code><span>三个键值对；每一个键对应一个数据列表，列表里面的每一个元素都是一个字典，该字典有4个键，即</span><code>id</code><span>、</span><code>report</code><span>、</span><code>image_path</code><span>、</span><code>split</code></p></li></ol></li></ol></li><li><p><span>按照这篇文章代码中所述</span></p><ol start='' ><li><p><span>图像全部放入</span><code>data/iu/images/iu_2image/images/</code></p></li><li><p><span>标注放到</span><code>data/iu/images/iu_2image/annotation.json</code></p></li></ol></li></ol><h2 id='22使用chexpert抽取标签'><span>2.2使用CheXpert抽取标签</span></h2><ol start='' ><li><p><span>论文中提到：为了保持一致性，我们使用 CheXpert 提取 IU-Xray 数据集的标签。因此需要使用</span><a href='https://github.com/stanfordmlgroup/chexpert-labeler'><span>chexpert-labeler</span></a><span>来抽取IU数据集的标签</span></p></li><li><p><span>chexpert-labeler作用：从报告中抽取观察的结果</span></p><ol start='' ><li><p><span>所谓观察结果就是：根据报告的描述，判断其中描述了哪种疾病，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230727162400339.png" referrerpolicy="no-referrer" alt="image-20230727162400339"></p></li><li><p><span>所以这篇文章中所说的标签就是</span><code>12</code><span>种疾病标签，以及</span><code>2</code><span>个单独设置的标签(</span><code>No finding</code><span>和</span><code>Support device</code><span>)</span></p></li><li><p><span>观察结果作为图像的结构化的标签。具体的</span><code>14</code><span>个标签如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230727164357819.png" referrerpolicy="no-referrer" alt="image-20230727164357819"></p></li></ol></li></ol><h3 id='221环境准备'><span>2.2.1环境准备</span></h3><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python" style="break-inside: unset;"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">## 创建虚拟环境</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># conda create -n chexpert-label pip python=3.8</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># 这里直接在autodl平台，选择pytorch-1.7.0 python 3.8，并没有自己创建虚拟环境</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># 由于bllipparser无法在Windows上编译，因此只能在linux或者mac上去跑这个项目了</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># 因此只在autodl上跑吧</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># 后来又装了deepin操作系统，然后在系统上重新跑了一遍，生成了需要的标签文件</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">conda</span> <span class="cm-variable">activate</span> <span class="cm-variable">chexpert</span><span class="cm-operator">-</span><span class="cm-variable">label</span> <span class="cm-comment"># 报错</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">source</span> <span class="cm-variable">activate</span> <span class="cm-variable">chexpert</span><span class="cm-operator">-</span><span class="cm-variable">label</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">conda</span> <span class="cm-variable">deactivate</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">conda</span> <span class="cm-variable">activate</span> <span class="cm-variable">chexpert</span><span class="cm-operator">-</span><span class="cm-variable">label</span> <span class="cm-comment"># 然后就不报错了</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># conda install nltk==3.3.0</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-operator">--</span><span class="cm-variable">user</span> <span class="cm-operator">-</span><span class="cm-variable">U</span> <span class="cm-variable">nltk</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">conda</span> <span class="cm-variable">install</span> <span class="cm-variable">pandas</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">bioc</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">pathlib2</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">bllipparser</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">pystanforddependencies</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">networkx</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">ply</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">sudo</span> <span class="cm-variable">apt</span><span class="cm-operator">-</span><span class="cm-variable">get</span> <span class="cm-variable">update</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">sudo</span> <span class="cm-variable">apt</span><span class="cm-operator">-</span><span class="cm-variable">get</span> <span class="cm-variable">install</span> <span class="cm-variable">openjdk</span><span class="cm-operator">-</span><span class="cm-number">8</span><span class="cm-operator">-</span><span class="cm-variable">jdk</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">uninstall</span> <span class="cm-variable">networkx</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">pip</span> <span class="cm-variable">install</span> <span class="cm-variable">networkx</span><span class="cm-operator">==</span><span class="cm-number">1.11</span> <span class="cm-comment"># 要指定版本，否则报错</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># 将total_loc = ann.get_total_location()改为total_loc = ann.total_span</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 622px;"></div><div class="CodeMirror-gutters" style="display: none; height: 622px;"></div></div></div></pre><p><span>之后运行</span><code>files_used/label.py</code><span>文件即可</span></p><h3 id='222iu数据集报告标签生成'><span>2.2.2IU数据集报告标签生成</span></h3><ol start='' ><li><p><span>如下图所示，是读取标签文件的过程：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230811153310680.png" referrerpolicy="no-referrer" alt="image-20230811153310680"></p></li><li><p><span>分析</span></p><ol start='' ><li><p><span>根据上图代码过程知道，这个csv文件中是有标题的</span></p></li><li><p><span>因为</span><code>pandas</code><span>版本的原因，这里的</span><code>label = row[1:].to_list()</code><span>需要改成</span><code>label = row[1:].tolist()</code></p></li></ol></li><li><p><span>分析完之后，构建代码来读取iu数据集的报告进行打标签。</span></p><ol start='' ><li><p><span>为了保险起见，会对所有的待打标签的报告都加上英文状态下的引号</span></p></li><li><p><span>一次性对所有的数据(训练集+验证集+测试集)的报告打标签，存放在一个csv文件中</span></p></li><li><p><span>下图是处理的前三条数据的结果，第二张图是处理之后存储在csv文件中的样子</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230811205648171.png" referrerpolicy="no-referrer" alt="image-20230811205648171"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230811205711320.png" referrerpolicy="no-referrer" alt="image-20230811205711320"></p></li><li><p><span>为了后续的需要，除了读取report键以外，还读取了id键</span></p></li><li><p><span>最后保存了三种结构的标签结果文件：</span><code>labeled_reports_with_report_with_id.csv</code><span>、</span><code>labeled_reports_with_report_without_id.csv</code><span>、</span><code>labeled_reports_without_report_with_id.csv</code></p><ol start='' ><li><p><span>最终用于实验的是包含id，但是不包含报告的。</span></p></li><li><p><span>三种文件如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230812202751942.png" referrerpolicy="no-referrer" alt="image-20230812202751942"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230812202812002.png" referrerpolicy="no-referrer" alt="image-20230812202812002"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230812202837209.png" referrerpolicy="no-referrer" alt="image-20230812202837209"></p></li></ol></li></ol></li></ol><h2 id='23运行配置-在编辑界面模仿命令行调用'><span>2.3运行配置-在编辑界面模仿命令行调用</span></h2><blockquote><p><span>参考：</span><a href='https://blog.csdn.net/weixin_43992162/article/details/119894794?ydreferer=aHR0cHM6Ly9jbi5iaW5nLmNvbS8%3D'><span>pycharm使用命令行运行和调试python程序</span><em><span>pycharm中如何在终端输入指令调试代码</span></em><span>Jeremy_权的博客-CSDN博客</span></a></p></blockquote><ol start='' ><li><p><span>右击要运行的文件，这里是</span><code>main.py</code><span>，选择下图的选项，修改运行配置</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230808204020611.png" referrerpolicy="no-referrer" alt="image-20230808204020611"></p></li><li><p><span>先勾选右侧的</span><code>parameters</code><span>，然后在左侧对应的位置将命令行调用时py文件之后的参数复制进去</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230808204139649.png" referrerpolicy="no-referrer" alt="image-20230808204139649"></p></li><li><p><span>之后，就可以右键运行或者调试该文件了。</span></p></li></ol><h1 id='3模型解析以iu-xray数据集为例'><span>3模型解析(以iu-xray数据集为例)</span></h1><h2 id='31从mainpy文件出发的'><span>3.1从</span><code>main.py</code><span>文件出发的</span></h2><ol start='' ><li><p><span>项目地址给出运行</span><code>main.py</code><span>文件的命令行代码（完整模型）：</span></p><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">python</span> <span class="cm-variable">main</span>.<span class="cm-property">py</span> <span class="cm-operator">--</span><span class="cm-variable">cfg</span> <span class="cm-variable">config</span><span class="cm-operator">/</span>{<span class="cm-error">$</span><span class="cm-variable">dataset_name</span>}<span class="cm-variable">_resnet</span>.<span class="cm-property">yml</span> <span class="cm-operator">--</span><span class="cm-variable">expe_name</span> {<span class="cm-error">$</span><span class="cm-variable">experiment</span> <span class="cm-variable">name</span>} <span class="cm-operator">--</span><span class="cm-variable">label_loss</span> <span class="cm-operator">--</span><span class="cm-variable">rank_loss</span> <span class="cm-operator">--</span><span class="cm-variable">version</span> <span class="cm-number">12</span></span></pre></div></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 23px;"></div><div class="CodeMirror-gutters" style="display: none; height: 23px;"></div></div></div></pre><ol start='' ><li><p><code>cfg</code><span>：要使用的配置文件</span></p></li><li><p><code>expe_name</code><span>：实验名称，应该是额外用来标识每次实验的</span></p></li><li><p><code>label_loss</code><span>：应该是在优化的时候是否计算标签损失的设置项；命令行中出现这个参数，则这个参数将被置为</span><code>True</code><span>（默认为</span><code>false</code><span>，因为</span><code>action=&#39;store_true&#39;</code><span>的原因）</span></p></li><li><p><code>rank_loss</code><span>：类似于</span><code>label_loss</code><span>的设置项（具体干什么用的还得看完代码才知道）</span></p></li><li><p><code>version</code><span>：视觉特征提取器模型的版本，默认为</span><code>0</code></p></li><li><p><span>如果要使用IU数据集，则命令变为：</span></p><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">python</span> <span class="cm-variable">main</span>.<span class="cm-property">py</span> <span class="cm-operator">--</span><span class="cm-variable">cfg</span> <span class="cm-variable">config</span><span class="cm-operator">/</span><span class="cm-variable">iu_resnet</span>.<span class="cm-property">yml</span> <span class="cm-operator">--</span><span class="cm-variable">expe_name</span> <span class="cm-variable">iu_main_1</span> <span class="cm-operator">--</span><span class="cm-variable">label_loss</span> <span class="cm-operator">--</span><span class="cm-variable">rank_loss</span> <span class="cm-operator">--</span><span class="cm-variable">version</span> <span class="cm-number">12</span></span></pre></div></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 23px;"></div><div class="CodeMirror-gutters" style="display: none; height: 23px;"></div></div></div></pre></li></ol></li><li><p><span>执行</span><code>main.py</code><span>函数，首先会将配置导入，其次设置随机数生成器种子</span></p></li><li><p><span>接下来构建分词器</span><code>Tokenizer</code></p></li></ol><h3 id='311分词器tokenizer'><span>3.1.1分词器Tokenizer</span></h3><ol start='' ><li><p><span>这里只是初始化一下分词器，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230810124625235.png" referrerpolicy="no-referrer" alt="image-20230810124625235"></p><ol start='' ><li><p><span>这里直接将annotation文件中的所有数据全部读取进来了(因为接下来是根据report的内容来构建词汇表)，如下图所示。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230810124914043.png" referrerpolicy="no-referrer" alt="image-20230810124914043"></p></li><li><p><span>接下来遍历所有的报告，分词，构建词汇表：</span></p><ol start='' ><li><p><span>下图是分词之后的结果</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230810130440212.png" referrerpolicy="no-referrer" alt="image-20230810130440212"></p></li><li><p><span>然后统计每个词出现的次数，并按照设定的阈值进行删减，再加入</span><code>&lt;unk&gt;</code><span>表示未在词表中的词，然后进行排序，最终得到的词表包含</span><code>760</code><span>个词(包含句号和</span><code>&lt;unk&gt;</code><span>)</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230810131136571.png" referrerpolicy="no-referrer" alt="image-20230810131136571"></p></li><li><p><span>然后构建词和索引之间的对应关系，用字典存储。</span></p><ol start='' ><li><p><span>第一个元素的索引从</span><code>1</code><span>开始</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230810131748130.png" referrerpolicy="no-referrer" alt="image-20230810131748130"></p></li></ol></li></ol></li></ol><h3 id='312数据加载器ladataloader'><span>3.1.2数据加载器LADataLoader</span></h3><blockquote><p><span>构建训练集、测试集、验证集的数据加载器，其中训练集的数据加载器会进行打乱的操作，即</span><code>shuffle=True</code></p><p><span>以训练集的数据加载器为例描述整个过程</span></p></blockquote><ol start='' ><li><p><span>首先初始化一些类变量，以及一个用于对输入图像进行标准化的变量</span><code>normalize</code><span>，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230810141132095.png" referrerpolicy="no-referrer" alt="image-20230810141132095"></p></li><li><p><span>接下来使用</span><code>torchvision.transforms.Compose</code><span>对象构建一个包含多个步骤的图像与处理序列：</span></p><ol start='' ><li><p><code>transforms.Resize(args.image_size)</code><span>：将图像的大小调整为</span><code>args.image_size</code><span>。其中</span><code>args.image_size</code><span>是一个参数，可以是任何整数或元组。但是是整数或者元组的时候进行的具体操作不同：</span></p><ol start='' ><li><p><span>如果</span><code>args.image_size</code><span>是一个整数，则将图像的</span><u><span>短边</span></u><span>调整为该整数，</span><u><span>长边按比例缩放</span></u><span>。</span></p></li><li><p><span>如果</span><code>args.image_size</code><span>是一个元组，则将图像的大小调整为该元组中的值。例如，如果</span><code>args.image_size</code><span>是</span><code>(256, 256)</code><span>，则将图像的大小调整为</span><code>256x256</code></p></li></ol></li><li><p><code>transforms.RandomCrop(args.crop_size)</code><span>：与</span><code>resize</code><span>类似，但有所不同。将图像随机裁剪为大小为</span><code>args.crop_size</code><span>的图像：</span></p><ol start='' ><li><p><span>如果</span><code>args.crop_size</code><span>是一个整数，则将图像裁剪为正方形，边长为该整数。</span></p></li><li><p><span>如果</span><code>args.crop_size</code><span>是一个元组，则将图像裁剪为该元组中的大小。</span></p></li></ol></li><li><p><code>transforms.RandomHorizontalFlip()</code><span>：是一个数据增强操作，它以</span><code>0.5</code><span>的概率随机水平翻转图像，如下图所示。</span></p><ol start='' ><li><p><span>具体来说，如果随机数小于</span><code>0.5</code><span>，则将图像水平翻转，否则不进行翻转。</span></p></li><li><p><span>水平翻转是指将图像沿着垂直中心轴进行翻转，即将图像左右翻转</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230810142027401.png" referrerpolicy="no-referrer" alt="image-20230810142027401"></p></li><li><p><code>transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 0.8), fillcolor=(0, 0, 0))</code><span>：随机仿射变换，包括旋转、平移和缩放，具体参数如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230810142354359.png" referrerpolicy="no-referrer" alt="image-20230810142354359"></p></li><li><p><span>最后，使用</span><code>transforms.ToTensor()</code><span>将图像转为张量，并用</span><code>normalize</code><span>变量进行标准化</span></p></li></ol></li><li><p><span>加载数据集（以IU数据集为例）</span></p><ol start='' ><li><p><span>调用</span><code>IuxrayMultiImageDataset</code><span>类创建数据集实例</span></p><ol start='' ><li><p><span>首先调用数据集基类，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230811114409106.png" referrerpolicy="no-referrer" alt="image-20230811114409106"></p></li><li><p><span>基类属性创建好之后，</span><code>IuxrayMultiImageDataset</code><span>类中还要初始化一下IU数据集报告的标签</span></p><ol start='' ><li><p><span>因此首先需要按照论文所说的，事先构建一下IU数据集的标签文件，详见 </span><a href='#222iu数据集报告标签生成'><span>2.2.2IU数据集报告标签生成</span></a></p></li><li><p><span>然后将只有</span><code>id</code><span>，没有报告的标签文件放到</span><code>data/iu/r2gen_split/id_label.csv</code></p></li></ol></li><li><p><span>读取标签文件</span></p><ol start='' ><li><p><span>按行读取，获取每一行的</span><code>id</code><span>、以及</span><code>14</code><span>种观察结果，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230819172514344.png" referrerpolicy="no-referrer" alt="image-20230819172514344"></p></li><li><p><span>然后得到一个标签字典</span><code>label_dict</code><span>，其中的</span><code>key</code><span>是放射图像(或者理解为患者)的</span><code>id</code><span>，</span><code>value</code><span>是一个标签列表，</span><code>1</code><span>表示有对应的观察结果。如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230819210926410.png" referrerpolicy="no-referrer" alt="image-20230819210926410"></p></li></ol></li></ol></li></ol></li><li><p><span>将数据加载器的相关重要参数放到</span><code>LADataLoader</code><span>类的</span><code>init_kwargs</code><span>变量中，然后调用父类的初始化函数返回一个数据加载器对象</span></p><ol start='' ><li><p><code>collate_fn</code><span>函数：用来处理</span><code>DataLoader</code><span>返回的每个batch的数据的</span></p></li><li><p><code>num_workers</code><span>：用于指定数据加载器使用的子进程数量，具体介绍如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230819214705050.png" referrerpolicy="no-referrer" alt="image-20230819214705050"></p></li><li><p><code>pin_memory</code><span>：设置为</span><code>True</code><span>，则会将数据复制到固定的内存区域（锁页内存），这样可以加速数据传输。具体如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230819214754338.png" referrerpolicy="no-referrer" alt="image-20230819214754338"></p></li></ol></li><li><p><span>至此，数据加载器就完成了创建。验证集和测试集类似，如下图所示（大部分的参数都在创建的过程中提到了）。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230820205001062.png" referrerpolicy="no-referrer" alt="image-20230820205001062"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230820205047774-2535850.png" referrerpolicy="no-referrer" alt="image-20230820205047774"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230820205107109.png" referrerpolicy="no-referrer" alt="image-20230820205107109"></p></li></ol><h4 id='3121collatefn函数解析'><span>3.1.2.1</span><code>collate_fn</code><span>函数解析</span></h4><p><span>见</span><a href='#31712数据的处理之collatefn方法'><span>3.1.7.1.2数据的处理之collate_fn方法</span></a></p><h3 id='313创建模型结构'><span>3.1.3创建模型结构</span></h3><blockquote><ol start='' ><li><p><span>这里创建模型结构的过程涉及到众多参数，也涉及到层层的类继承</span></p></li><li><p><code>lamrg.py</code><span>文件应该是本论文自己的模型</span></p></li></ol></blockquote><ol start='' ><li><p><span>这里的创建过程为：递归调用</span><code>LAMRGModel_v12</code><span>类的初始化函数、</span><code>LAMRGModel_v9</code><span>类的初始化函数、</span><code>_LAMRG</code><span>类的初始化函数</span></p></li></ol><h4 id='3131调用lamrg类的初始化函数'><span>3.1.3.1调用</span><code>_LAMRG</code><span>类的初始化函数</span></h4><blockquote><ol start='' ><li><p><span>包括初始化参数</span><code>args</code><span>、分词器</span><code>tokenizer</code><span>、视觉特征提取器</span><code>visual_extractor</code><span>、transformer的编码器解码器结构</span><code>encoder_decoder</code><span>、以及一个处理14种观察结果的线性层</span></p><ol start='' ><li><p><span>参数在很多类中都在不断地传递，因为在这些类中需要用到参数里面的一些设置</span></p></li></ol></li></ol></blockquote><h5 id='31311visualextractor的创建'><span>3.1.3.1.1</span><code>visual_extractor</code><span>的创建</span></h5><blockquote><ol start='' ><li><p><span>这里使用的模型是</span><code>resnet101</code></p></li></ol></blockquote><ol start='' ><li><p><span>模型创建过程如下，代码如下图所示</span></p><ol start='' ><li><p><span>从官方获取</span><code>resnet101</code><span>模型，并加载官方的预训练权重</span></p></li><li><p><span>然后去除掉模型最后两个层，只保留前面的层，用于特征提取</span></p></li><li><p><span>另外，还建立了一个平均池化层和一个线性层，用于对提取的特征进行降采样和分类</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230821111247672.png" referrerpolicy="no-referrer" alt="image-20230821111247672"></p></li><li><p><span>关于平均池化(</span><font color="red"><span>以后可以细看一下</span></font><span>)：</span></p><ol start='' ><li><p><span>平均池化的作用如下：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821111416131.png" referrerpolicy="no-referrer" alt="image-20230821111416131"></p></li><li><p><code>torch.nn.AvgPool2d(kernel_size=7, stride=1, padding=0)</code><span>函数解析如下：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821111517939.png" referrerpolicy="no-referrer" alt="image-20230821111517939"></p></li></ol></li><li><p><span>关于从官方下载并加载</span><code>resnet</code><span>模型，使用这句话来加载官方的模型和权重：</span><code>model = getattr(models, self.visual_extractor)(pretrained=self.pretrained)</code></p><ol start='' ><li><p><code>models</code><span>是</span><code>torchvision</code><span>下面的包，其中有一个</span><code>init</code><span>函数，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821111942522.png" referrerpolicy="no-referrer" alt="image-20230821111942522"></p></li><li><p><span>进入</span><code>resnet</code><span>包，其中提供了各个</span><code>resnet</code><span>模型的权重的下载链接(如下第一张图)，通过代码调试，发现下载好的权重的存储位置(如下第二张图)</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821112121815.png" referrerpolicy="no-referrer" alt="image-20230821112121815"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821112330086.png" referrerpolicy="no-referrer" alt="image-20230821112330086"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821112348756.png" referrerpolicy="no-referrer" alt="image-20230821112348756"></p></li></ol></li></ol><h5 id='31312-encoderdecoder的创建'><span>3.1.3.1.2 encoder_decoder的创建</span></h5><ol start='' ><li><p><span>使用</span><code>TransformerModel</code><span>类创建编码器解码器结构时，涉及到好几个类之间的继承，如下图所示，</span><code>TransformerModel</code><span>继承自</span><code>AttModel</code><span>，进一步继承自</span><code>CaptionModel</code><span>，最终继承自</span><code>nn.Module</code><span>。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821151038355.png" referrerpolicy="no-referrer" alt="image-20230821151038355"></p></li><li><p><span>关于python类的继承：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821151625032.png" referrerpolicy="no-referrer" alt="image-20230821151625032"></p></li><li><p><span>进入</span><code>CaptionModel</code><span>的初始化函数，没有什么额外的属性定义</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821154926452.png" referrerpolicy="no-referrer" alt="image-20230821154926452"></p></li><li><p><span>然后进入</span><code>AttModel</code><span>的初始化函数，定义了注意力模型的一些参数，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821155133131.png" referrerpolicy="no-referrer" alt="image-20230821155133131"></p></li><li><p><span>之后才进入到transformer的模型构建当中：</span></p><ol start='' ><li><p><span>编码器层和解码器层都是</span><code>opt.num_layers=3</code><span>，特征维度是</span><code>opt.d_model=512</code><span>，其余的参数如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821201919248.png" referrerpolicy="no-referrer" alt="image-20230821201919248"></p></li><li><p><span>然后创建一个序列用于对特征进行嵌入操作(感觉顶多算一个线性变换，将特征的维度从</span><code>self.att_feat_size</code><span>变成</span><code>self.d_model</code><span>)，序列中</span></p><ol start='' ><li><p><strong><span>首先</span></strong><span>是一个批次标准化层（</span><u><span>可选，这里默认不进行此操作</span></u><span>），输入特征的维度是</span><code>self.att_feat_size=2048</code></p></li><li><p><span>其次是一个线性层，输入特征维度是</span><code>self.att_feat_size</code><span>，输出维度是</span><code>self.d_model=512</code></p></li><li><p><span>然后是一个</span><code>Dropout</code><span>层。如下图所示是建立好的</span><code>nn.Sequential</code></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821214417189.png" referrerpolicy="no-referrer" alt="image-20230821214417189"></p></li><li><p><span>关于</span><code>nn.BatchNorm1d</code><span>标准化层</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821214544263.png" referrerpolicy="no-referrer" alt="image-20230821214544263"></p></li><li><p><span>关于</span><code>nn.Sequential(*(......))</code></p><ol start='' ><li><p><code>*</code><span>号用于对其后面的元组</span><code>(......)</code><span>进行解包，将其中的每个元素传递给</span><code>nn.Sequential</code></p></li><li><p><span>之所以把</span><code>(nn.BatchNorm1d(self.att_feat_size))</code><span>写成</span><code>(nn.BatchNorm1d(self.att_feat_size),)</code><span>，是因为现成前者的话无法识别为元组，也就无法与后面的</span><code>(nn.Linear(self.att_feat_size, self.d_model),nn.Dropout(self.dropout))</code><span>相加了。下图是一个测试例子</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821215048728.png" referrerpolicy="no-referrer" alt="image-20230821215048728"></p></li><li><p><span>所以也可以把这几个层单独拎出来写，就像下图给出的官方的例子一样</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230821215836065.png" referrerpolicy="no-referrer" alt="image-20230821215836065"></p></li></ol></li></ol></li><li><p><span>然后构建了一个线性层，输入是模型的特征</span><code>d_model</code><span>，输出维度是目标词汇表的大小</span><code>tgt_vocab</code></p></li><li><p><span>然后传入超参数，构建transformer模型</span></p><ol start='' ><li><p><span>和之前看的transformer代码基本一样</span></p></li><li><p><span>唯一的区别在于下图：</span><code>src_embed</code><span>不再是输入序列的</span><code>Embeddings</code><span>了，因为本论文中输入是图像了，会有额外的对图像的操作</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230822143442195.png" referrerpolicy="no-referrer" alt="image-20230822143442195"></p></li><li><p><span>所以看最后建立的</span><code>EncoderDecoder</code><span>类，结构中并没有</span><code>src_embed</code><span>，只有</span><code>tgt_embed</code><span>，所以</span><code>lambda x: x</code><span>真的只是一个占位符</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230822144319632.png" referrerpolicy="no-referrer" alt="image-20230822144319632"></p></li></ol></li></ol></li></ol><h5 id='31313其他'><span>3.1.3.1.3其他</span></h5><ol start='' ><li><p><span>然后创建了一个线性层，输入是疾病标签数(</span><code>14</code><span>种观察结果)，输出是</span><code>d_vf</code><span>(应该是视觉特征的维度吧？，不过是用于</span><code>densenet</code><span>或者</span><code>efficientnet</code><span>的，</span><code>main.py</code><span>中使用的是</span><code>resnet101</code><span>)</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230822145829637.png" referrerpolicy="no-referrer" alt="image-20230822145829637"></p></li><li><p><span>并对这个线性层进行人为的初始化操作</span></p><ol start='' ><li><p><span>使用</span><code>nn.init.kaiming_normal_</code><span>函数对创建的线性层的随机初始化得到的权重进行处理，具体如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230822150935785.png" referrerpolicy="no-referrer" alt="image-20230822150935785"></p></li><li><p><span>使用</span><code>f.bias.data.fill_(0)</code><span>将偏置都变成</span><code>0</code></p></li><li><p><span>最终前后对比，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230822151026858.png" referrerpolicy="no-referrer" alt="image-20230822151026858"></p></li></ol></li></ol><h4 id='3132调用lamrgmodelv9类的初始化函数'><span>3.1.3.2调用</span><code>LAMRGModel_v9</code><span>类的初始化函数</span></h4><blockquote><ol start='' ><li><p><span>从</span><code>_LAMRG</code><span>类继承过来之后，其中的成员属性和函数也被继承过来，因此目前已经具备分词器</span><code>tokenizer</code><span>、视觉特征提取器</span><code>visual_extractor</code><span>、transformer的编码器解码器结构</span><code>encoder_decoder</code></p></li></ol></blockquote><ol start='' ><li><p><span>首先是一些基本的参数的设置</span></p><ol start='' ><li><p><span>其中关于</span><code>num_slots</code><span>，</span><font color="red"><span>目前还不知道是什么意思</span></font></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230822162446072.png" referrerpolicy="no-referrer" alt="image-20230822162446072"></p></li></ol><h5 id='31321textencoder的创建'><span>3.1.3.2.1</span><code>TextEncoder</code><span>的创建</span></h5><blockquote><ol start='' ><li><p><span>用途：用于对报告文本的编码</span></p></li></ol></blockquote><ol start='' ><li><p><code>TextEncoder</code><span>包含如下内容：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230822164459083.png" referrerpolicy="no-referrer" alt="image-20230822164459083"></p><ol start='' ><li><p><span>用于对报告文本进行编码的编码器：和前面创建的transformer模型的编码器结构是一样的。虽然某些参数名称不一样，但使用的数值是一样的</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230822164831138.png" referrerpolicy="no-referrer" alt="image-20230822164831138"></p></li><li><p><span>一个分类器(</span><font color="red"><span>用途目前不清楚？</span></font><span>)，从</span><code>d_model</code><span>到</span><code>14</code><span>种观察结果</span><code>num_labels</code></p></li><li><p><span>一个对报告文本的嵌入层：由于报告文本在此任务中是需要生成的内容，因此词汇表是用</span><code>tgt_vocab</code><span>来代表的，而此处是对输入的报告文本进行编码，因此嵌入的结果用</span><code>src_embed</code><span>来表示。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230822165837950.png" referrerpolicy="no-referrer" alt="image-20230822165837950"></p></li></ol></li></ol><h5 id='31322memory的创建'><span>3.1.3.2.2</span><code>memory</code><span>的创建</span></h5><blockquote><ol start='' ><li><p><span>memory应该就是论文中说的知识库</span></p></li></ol></blockquote><ol start='' ><li><p><font color="red"><span>尚不清楚</span><code>self.prior_memory</code><span>和</span><code>self.select_prior</code><span>的作用？</span></font></p></li><li><p><code>self.prior_memory</code><span>和</span><code>self.select_prior</code><span>本质上都是一个多头注意力层+一个残差连接层，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230822204132438.png" referrerpolicy="no-referrer" alt="image-20230822204132438"></p></li><li><p><span>然后初始化记忆矩阵(</span><font color="red"><span>尚不清楚如何发挥作用，后续再看</span></font><span>)，初始化的过程为(如下图所示)：</span></p><ol start='' ><li><p><span>用参数矩阵(是一个单位矩阵)来表示记忆矩阵</span></p></li><li><p><span>然后根据</span><code>d_model</code><span>和</span><code>num_slots</code><span>之间的大小关系，对参数矩阵进行0填充或者截断</span></p></li><li><p><span>然后构建一个</span><code>mask</code><span>矩阵，维度是</span><code>(num_slots, d_model)</code><span>，前</span><code>num_slots</code><span>列为</span><code>1</code><span>，其余为</span><code>0</code></p></li><li><p><span>注意：由于最初是调用</span><code>LAMRGModel_v12</code><span>来构建模型的，而</span><code>LAMRGModel_v12</code><span>又继承了</span><code>LAMRGModel_v9</code><span>，两个类都有</span><code>init_memory</code><span>函数，因此</span><code>LAMRGModel_v12</code><span>重写了</span><code>LAMRGModel_v9</code><span>的</span><code>init_memory</code><span>函数，所以即使是在递归调用</span><code>LAMRGModel_v9</code><span>的初始化函数的时候，初始化记忆矩阵使用的是重写之后的</span><code>init_memory</code><span>函数，即</span><code>LAMRGModel_v12</code><span>中的</span><code>init_memory</code><span>函数。</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230822212055037.png" referrerpolicy="no-referrer" alt="image-20230822212055037"></p></li></ol><h5 id='31323其他'><span>3.1.3.2.3其他</span></h5><ol start='' ><li><p><span>创建了四个不同输入输出组合的线性层(</span><font color="red"><span>用于不同的地方，目前不清楚？</span></font><span>)，并手动初始化其中的三个</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230822214344829.png" referrerpolicy="no-referrer" alt="image-20230822214344829"></p></li></ol><h4 id='3133调用lamrgmodelv12类的初始化函数'><span>3.1.3.3调用</span><code>LAMRGModel_v12</code><span>类的初始化函数</span></h4><blockquote><ol start='' ><li><p><span>初始化函数中基本的参数设置与</span><code>LAMRGModel_v9</code><span>一样，不同之处在于：</span></p><ol start='' ><li><p><code>memory</code><span>相关的设置</span></p></li><li><p><span>线性层的设置</span></p></li><li><p><span>增加了分类器和标签嵌入</span></p></li></ol></li></ol></blockquote><h5 id='31331memory相关的设置'><span>3.1.3.3.1</span><code>memory</code><span>相关的设置</span></h5><blockquote><ol start='' ><li><p><span>与</span><code>LAMRGModel_v9</code><span>相比，增加了</span><code>update_memory</code><span>属性，重写了</span><code>select_prior</code><span>属性</span></p></li></ol></blockquote><ol start='' ><li><p><span>新增的</span><code>update_memory</code><span>和之前的</span><code>prior_memory</code><span>以及要重写的</span><code>select_prior</code><span>一样，都是</span><code>MHA-FF</code><span>类，即都是一个多头注意力机制然后施加残差连接</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230823103641167.png" referrerpolicy="no-referrer" alt="image-20230823103641167"></p></li><li><p><span>进一步的，在参数设置上，三者完全一样，虽然</span><code>update_memory</code><span>和重写的</span><code>select_prior</code><span>的</span><code>head</code><span>参数变成了</span><code>args.num_memory_heads</code><span>，但是</span><code>args.num_memory_heads</code><span>和</span><code>args.num_heads</code><span>默认值是一样的</span></p></li><li><p><span>在</span><code>memory</code><span>的初始化方面，在</span><code>LAMRGModel_v12</code><span>类中，对在</span><code>LAMRGModel_v9</code><span>类中初始化出来的</span><code>self.memory</code><span>进行了重写，即重新调用</span><code>self.init_memory()</code><span>函数，并将返回的</span><code>memory</code><span>和</span><code>mask</code><span>分开存放</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230823103819141.png" referrerpolicy="no-referrer" alt="image-20230823103819141"></p></li></ol><h5 id='31332线性层的设置'><span>3.1.3.3.2线性层的设置</span></h5><ol start='' ><li><p><span>与</span><code>LAMRGModel_v9</code><span>类相比，多了</span><code>self.get_mem</code><span>、</span><code>self.linear_z</code><span>线性层，并重写了</span><code>self.linear_feat</code><span>(其实重写之后还是原来那个)</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230823111616604.png" referrerpolicy="no-referrer" alt="image-20230823111616604"></p></li></ol><h5 id='31333其他'><span>3.1.3.3.3其他</span></h5><ol start='' ><li><p><span>分类器</span></p><ol start='' ><li><p><span>构建了一个输入是</span><code>d_model</code><span>，输出是</span><code>14</code><span>种观察结果的</span><code>num_labels</code></p></li></ol></li><li><p><span>标签嵌入层</span></p><ol start='' ><li><p><span>是一个线性层，输入是</span><code>1</code><span>，输出是</span><code>d_model</code></p></li><li><p><span>即将某一个标签映射到</span><code>d_model</code><span>的特征维度上</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230823111642097.png" referrerpolicy="no-referrer" alt="image-20230823111642097"></p></li><li><p><span>手动初始化上面建立的线性层、分类器、标签嵌入层</span></p><ol start='' ><li><p><span>在初始化权重函数内部，调用的是</span><code>_LAMRG</code><span>类中的</span><code>_init_weight</code><span>函数，既调整了权重，也将偏置置为</span><code>0</code></p><p><img src="1-report_generation_for_M2KT.assets/image-20230823112400212.png" referrerpolicy="no-referrer" alt="image-20230823112400212"></p></li></ol></li></ol><h4 id='3134模型创建结果'><span>3.1.3.4模型创建结果</span></h4><ol start='' ><li><p><span>至此就完成了模型的创建，结果如下图</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230823112639787.png" referrerpolicy="no-referrer" alt="image-20230823112639787"></p></li></ol><h3 id='314创建损失函数和评价矩阵'><span>3.1.4创建损失函数和评价矩阵</span></h3><ol start='' ><li><p><span>下图中的写法只是给函数起了别名，方便理解，</span><font color="red"><span>具体内部怎么计算的，等计算的时候再描述</span></font></p><p><img src="1-report_generation_for_M2KT.assets/image-20230823152348772.png" referrerpolicy="no-referrer" alt="image-20230823152348772"></p></li></ol><h3 id='315构建优化器和学习率调度器'><span>3.1.5构建优化器和学习率调度器</span></h3><blockquote><ol start='' ><li><p><span>优化器用于模型参数的更新，学习率调度器用于动态调整参数更新过程中学习率的值</span></p></li></ol></blockquote><h4 id='3151优化器'><span>3.1.5.1优化器</span></h4><ol start='' ><li><p><span>这里将模型参数划分成视觉特征的参数、视觉特征以外的其它参数</span></p><ol start='' ><li><p><span>两类参数的初始学习率不同</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230823162245286.png" referrerpolicy="no-referrer" alt="image-20230823162245286"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230823162304463.png" referrerpolicy="no-referrer" alt="image-20230823162304463"></p></li></ol><h4 id='3152调度器'><span>3.1.5.2调度器</span></h4><ol start='' ><li><p><span>这里采用的调度器是</span><code>StepLR</code><span>或者余弦退火，默认是</span><code>StepLR</code></p></li><li><p><font color="red"><span>以后可以详细看一下调度器的内容</span></font></p><p><img src="1-report_generation_for_M2KT.assets/image-20230823201700792.png" referrerpolicy="no-referrer" alt="image-20230823201700792"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230823201731872.png" referrerpolicy="no-referrer" alt="image-20230823201731872"></p></li></ol><h3 id='316构建trainer用于训练管理'><span>3.1.6构建Trainer用于训练管理</span></h3><blockquote><ol start='' ><li><p><code>Trainer</code><span>类继承了</span><code>BaseTrainer</code><span>类，因此调用</span><code>Trainer</code><span>的初始化函数之前，会先调用</span><code>BaseTrainer</code><span>类的初始化函数</span></p></li></ol></blockquote><h4 id='3161tensorboardx相关知识'><span>3.1.6.1tensorboardX相关知识</span></h4><ol start='' ><li><p><code>tensorboardX</code><span>是一个PyTorch的可视化工具库，用于将PyTorch中的训练过程可视化。</span></p><ol start='' ><li><p><code>tensorboardX</code><span>可以将PyTorch中的训练日志数据写入到TensorBoard可视化工具中，从而可以方便地查看模型的训练过程和性能指标。</span></p></li></ol></li><li><p><code>tensorboardX</code><span>库提供了一个</span><code>SummaryWriter</code><span>类，用于将训练日志数据写入到TensorBoard中。</span></p><ol start='' ><li><p><span>通过在训练过程中调用</span><code>SummaryWriter</code><span>类的方法，可以将模型的损失函数、精度、学习率等指标写入到TensorBoard中，从而可以方便地查看这些指标的变化趋势和相互关系。</span></p></li></ol></li><li><p><span>此外，</span><code>tensorboardX</code><span>还支持可视化模型结构、梯度直方图、图像、音频等数据，可以帮助用户更加全面地了解模型的训练过程和性能表现。</span></p></li></ol><h4 id='3162调用basetrainer类的初始化函数'><span>3.1.6.2调用</span><code>BaseTrainer</code><span>类的初始化函数</span></h4><ol start='' ><li><p><span>记录参数信息：使用</span><code>self.print_args2tensorbord()</code><span>遍历了 </span><code>self.args</code><span> 中的所有参数，并将它们的名称和值以文本的形式添加到 TensorBoard 中</span></p><ol start='' ><li><p><span>文件位置：下图框出来的是</span><code>SummaryWriter</code><span>将数据保存的位置</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230824101829466.png" referrerpolicy="no-referrer" alt="image-20230824101829466"></p></li></ol></li><li><p><span>设置GPU，关键点：</span></p><ol start='' ><li><p><span>将张量分配到GPU上；这里直接用</span><code>device = torch.device(&#39;cuda:0&#39; if n_gpu_use &gt; 0 else &#39;cpu&#39;)</code><span>将张量分配到第一个GPU上，</span><font color="red"><span>如果是多GPU时，后续应该还会有其他的相应操作吧？</span></font></p></li><li><p><span>多GPU时对模型的处理：</span><code>self.model = torch.nn.DataParallel(model, device_ids=device_ids)</code></p></li><li><p><span>本文默认使用一个GPU进行训练</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230824103942384.png" referrerpolicy="no-referrer" alt="image-20230824103942384"></p></li><li><p><span>其它参数，如下图所示。其中：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230824201308752.png" referrerpolicy="no-referrer" alt="image-20230824201308752"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230824201330563.png" referrerpolicy="no-referrer" alt="image-20230824201330563"></p><ol start='' ><li><p><code>self.mnt_mode = args.monitor_mode</code><span>：所监视的指标的模式，有两个选择：最大化或者最小化。解释如下；简单说来就是告诉模型用什么类型的指标监视模型的训练情况</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230824104756975.png" referrerpolicy="no-referrer" alt="image-20230824104756975"></p></li></ol></li></ol><h4 id='3163调用trainer类的初始化函数'><span>3.1.6.3调用</span><code>Trainer</code><span>类的初始化函数</span></h4><ol start='' ><li><p><span>在基类的基础上，这里只需要记录一下下面四个量：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230824202426070.png" referrerpolicy="no-referrer" alt="image-20230824202426070"></p></li></ol><h3 id='317开始训练过程'><span>3.1.7开始训练过程</span></h3><blockquote><ol start='' ><li><p><code>trainer</code><span>对象将调用从基类</span><code>BaseTrainer</code><span>中继承过来的</span><code>train</code><span>方法，在</span><code>train</code><span>方法中，有语句</span><code>result = self._train_epoch(epoch)</code><span>，此语句将调用</span><code>Trainer</code><span>类实现的</span><code>_train_epoch</code><span>方法(在基类</span><code>BaseTrainer</code><span>中，</span><code>_train_epoch</code><span>方法是一个抽象方法，必须在子类中进行实现，否则会报错)</span></p></li></ol></blockquote><h4 id='3171trainepoch方法的实现过程'><span>3.1.7.1</span><code>_train_epoch</code><span>方法的实现过程</span></h4><ol start='' ><li><p><span>第一部分：将模型设置为训练模式，创建记录损失的变量，以及一个进度条(基于</span><code>train_dataloader</code><span>创建，用于展示训练数据的加载进度，而训练时数据又是训练一批加载一批，因此也就是用于展示训练进度了)；如下图所示</span></p><ol start='' ><li><p><span>进度条范围是</span><code>0~130</code><span>，正好符合训练数据加载器需要采样</span><code>130</code><span>次</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230825132954093.png" referrerpolicy="no-referrer" alt="image-20230825132954093"></p></li><li><p><span>然后在执行</span><code>for batch_idx, (images_id, images, reports_ids, reports_masks, labels) in enumerate(t):</code><span>语句时会去读取第一批数据。</span></p><ol start='' ><li><p><span>先进行数据的读取，见：</span><a href='#31711数据的读取之getitem方法'><span>3.1.7.1.1数据的读取之getitem方法</span></a></p></li><li><p><span>再进行数据的处理，见：</span><a href='#31712数据的处理之collatefn方法'><span>3.1.7.1.2数据的处理之collate_fn方法</span></a></p></li></ol></li><li><p><span>获取到数据之后，将其转移到GPU上</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230828102456994.png" referrerpolicy="no-referrer" alt="image-20230828102456994"></p></li><li><p><span>然后将优化器重的梯度清零：</span><code>self.optimizer.zero_grad()</code></p></li><li><p><span>然后将图像数据、报告数据、标签数据传入模型，如下图所示；进行模型的前向计算(见：</span><a href='#31713lamrgmodelv12模型的前向计算'><span>3.1.7.1.3LAMRGModel_v12模型的前向计算</span></a><span>)</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230828103158632.png" referrerpolicy="no-referrer" alt="image-20230828103158632"></p></li><li><p><span>接下来，进行损失的计算，详见</span><a href='#41损失计算过程'><span>4.1损失计算过程</span></a><span>小节。</span></p></li><li><p><span>损失计算完成后，将损失计算得到的值加入到训练损失的累加器</span><code>train_loss</code><span>中， 并进行反向传播，传播到计算过程中的各个量中</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908204032724.png" referrerpolicy="no-referrer" alt="image-20230908204032724"></p></li><li><p><span>然后使用</span><code>torch.nn.utils.clip_grad_value_</code><span>函数进行梯度裁剪，防止梯度爆炸，具体作用如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908204301633.png" referrerpolicy="no-referrer" alt="image-20230908204301633"></p></li><li><p><span>然后更新参数(所以这里每一批数据都进行梯度更新，不像transformer那篇文章那样，是累计几次之后再更新)</span></p></li><li><p><span>然后使用</span><code>tqdm</code><span>库的</span><code>set_description()</code><span>方法设置进度条的描述信息，可以看到下图中红框的位置加上了损失信息</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908210125367.png" referrerpolicy="no-referrer" alt="image-20230908210125367"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908210250812.png" referrerpolicy="no-referrer" alt="image-20230908210250812"></p></li><li><p><span>以上是一个批次的数据需要进行的所有操作，每处理一个批次的数据，都会得到一个损失值，会在进度条中显示出来，如下图所示是两次连续的进度条的变动情况：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908212904912.png" referrerpolicy="no-referrer" alt="image-20230908212904912"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908212923271.png" referrerpolicy="no-referrer" alt="image-20230908212923271"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908212936787.png" referrerpolicy="no-referrer" alt="image-20230908212936787"></p></li><li><p><span>将所有批次的数据训练完之后，会计算一下平均损失：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230909084043137.png" referrerpolicy="no-referrer" alt="image-20230909084043137"></p></li><li><p><span>接下来，使用验证集和测试集评估一下这个epoch下的模型。详见</span><a href='#42当前epoch下对模型进行验证'><span>4.2当前epoch下对模型进行验证</span></a><span>。当前epoch的测试过程和验证过程一样，就是使用的是测试集而已。</span></p></li><li><p><span>评估完成之后，将验证和测试过程中的指标值存到日志当中；然后使用</span><code>self.lr_scheduler.step()</code><span>更新学习率</span></p></li><li><p><span>至此，当前epoch执行完毕，返回日志对象(本质上是一个字典)到</span><a href="#anchor8"><code>BaseTrainer</code><span>的</span><code>train</code><span>方法</span></a></p><ol start='' ><li><p><span>对应到</span><code>BaseTrainer</code><span>的</span><code>train</code><span>方法中，就是下图所示的</span><code>result</code></p></li><li><p><code>result</code><span>包含训练损失、验证和测试的指标结果</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230912113146158.png" referrerpolicy="no-referrer" alt="image-20230912113146158"></p></li></ol><h5 id='31711数据的读取之getitem方法'><span>3.1.7.1.1数据的读取之getitem方法</span></h5><blockquote><ol start='' ><li><p><code>getitem</code><span>方法位于</span><code>datasets.py</code><span>文件的</span><code>IuxrayMultiImageDataset</code><span>类中</span></p></li><li><p><span>torch里面的方法在fetch数据的时候，需要调用多次</span><code>getitem</code><span>方法，每调用一次</span><code>getitem</code><span>方法，就读取了一条数据</span></p></li><li><p><font color="red"><span>这里有一个问题，每次fetch数据的时候都只读取前两张图像，但是有的患者文件夹中存在2张以上的图像，因此直接这样读取的话，2张以外的图像就没用了，而且存在读取的两张图像，有的是两个视角的图像，有的则不是</span></font><span>。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827205046955.png" referrerpolicy="no-referrer" alt="image-20230827205046955"></p></li></ol></blockquote><ol start='' ><li><p><span>首先pytorch框架会采样一个索引值，作为</span><code>idx</code><span>参数传递进入</span><code>getitem</code><span>方法，例如此时是</span><code>956</code></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827164230156.png" referrerpolicy="no-referrer" alt="image-20230827164230156"></p></li><li><p><span>然后，获取此索引值对应的一条数据，并获取该条数据中的患者id、图像路径，然后读取对应的图像数据，并按照之前设定的变换方法对读取进来的图像进行变换</span></p><ol start='' ><li><p><span>下图是变换前的图像数据，格式还是一个</span><code>PIL.Image.Image</code><span>对象</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827164711934.png" referrerpolicy="no-referrer" alt="image-20230827164711934"></p></li><li><p><span>然后使用下图所示的变换进行变换操作：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827164748293.png" referrerpolicy="no-referrer" alt="image-20230827164748293"></p></li><li><p><span>变换之后的图像数据如下图所示：维度是</span><code>(3,224,224)</code><span>，其中，</span><code>3</code><span>代表</span><code>3</code><span>个通道，即RGB通道，</span><code>224</code><span>代表图像的维度是</span><code>224*224</code></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827164831167.png" referrerpolicy="no-referrer" alt="image-20230827164831167"></p></li></ol></li><li><p><span>接着，将两张图像的数据进行堆叠，作为最终的图像数据。如下图所示：维度是</span><code>(2,3,224,224)</code></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827165053756.png" referrerpolicy="no-referrer" alt="image-20230827165053756"></p></li><li><p><span>然后获取了该条数据的报告文本对应的词典索引值、掩码矩阵、报告文本的长度（包含开始和结束符），如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827170620515.png" referrerpolicy="no-referrer" alt="image-20230827170620515"></p></li><li><p><span>然后，读取该条数据对应的标签列表</span></p><ol start='' ><li><p><span>源代码中，先获取了该条数据的患者id中的数值部分，然后去字典中读取标签，由此可知，其标签文件的id列是数值，这与我自己构建的标签文件的第一列不同(我自己的第一列就是完整的id字符串)，因此需要修改</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827170902889.png" referrerpolicy="no-referrer" alt="image-20230827170902889"></p></li><li><p><span>修改之后如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827171628786.png" referrerpolicy="no-referrer" alt="image-20230827171628786"></p></li></ol></li><li><p><span>最后以元组形式返回：</span><code>(患者id、堆叠后的图像张量、报告文本对应的索引值、报告掩码张量、报告长度、标签张量)</code><span>，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827171925069.png" referrerpolicy="no-referrer" alt="image-20230827171925069"></p></li></ol><h5 id='31712数据的处理之collatefn方法'><span>3.1.7.1.2数据的处理之collate_fn方法</span></h5><blockquote><p><code>collate_fn</code><span>方法用于数据(一批数据)读取进来之后的一些后处理操作；</span></p></blockquote><ol start='' ><li><p><span>torch读取进来的一批数据以列表形式存储在一起，列表中每个元素就是</span><code>getitem</code><span>方法返回的一个元组，</span><code>16</code><span>就是</span><code>batch_size</code><span>。如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827203935074.png" referrerpolicy="no-referrer" alt="image-20230827203935074"></p></li><li><p><span>对这一批数据进行解包：</span></p><ol start='' ><li><p><span>解包得到这批数据对应的患者id，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827204515237.png" referrerpolicy="no-referrer" alt="image-20230827204515237"></p></li><li><p><span>解包得到这批数据对应的图像数据，是一个元组，其中每个元素就是之间在</span><code>getitem</code><span>方法中堆叠得到的两张图像数据组成的张量。如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827204557409.png" referrerpolicy="no-referrer" alt="image-20230827204557409"></p></li><li><p><span>解包得到这批数据对应的报告文本在词典中的索引值，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827204616907.png" referrerpolicy="no-referrer" alt="image-20230827204616907"></p></li><li><p><span>解包得到这批数据对应的报告文本的掩码张量，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827204631269.png" referrerpolicy="no-referrer" alt="image-20230827204631269"></p></li><li><p><span>解包得到这批数据对应的报告文本的长度，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827204645055.png" referrerpolicy="no-referrer" alt="image-20230827204645055"></p></li><li><p><span>解包得到这批数据对应的疾病标签数据，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827204701131.png" referrerpolicy="no-referrer" alt="image-20230827204701131"></p></li></ol></li><li><p><span>然后将这批数据堆叠在一起，得到最终的图像数据张量，维度是</span><code>(16,2,3,224,224)</code><span>，如下图所示；</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827210632535.png" referrerpolicy="no-referrer" alt="image-20230827210632535"></p></li><li><p><span>接着获取本批次数据报告文本的最大序列长度</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827210654721.png" referrerpolicy="no-referrer" alt="image-20230827210654721"></p></li><li><p><span>然后构建目标以及目标掩码张量(这里是报告生成任务，因此报告文本就是目标)，并将报告文本的索引值赋给目标</span></p><ol start='' ><li><p><span>如下图是初始化的目标张量、目标的掩码张量，维度都是</span><code>(batch_size,max_seq_length)</code><span>，这里则是</span><code>(16,50)</code><span>。注意：由于报告文本的索引序列在生成的时候如果不超过设置的最大序列长度，则会原样保留，也就是说长度可能会不一样，因此这里的</span><code>50</code><span>只是一种情况。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827211055330.png" referrerpolicy="no-referrer" alt="image-20230827211055330"></p></li><li><p><span>接着，将这一批数据的报告索引值以及报告掩码矩阵赋值给新创建的</span><code>targets</code><span>、</span><code>targets_masks</code><span>；因此这里构建</span><code>targets</code><span>、</span><code>targets_masks</code><span>的目的就是以符合模型输入的格式重新组织模型的目标数据</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827211918341.png" referrerpolicy="no-referrer" alt="image-20230827211918341"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827212220718.png" referrerpolicy="no-referrer" alt="image-20230827212220718"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827212322324.png" referrerpolicy="no-referrer" alt="image-20230827212322324"></p></li><li><p><span>然后将这批数据的标签数据进行堆叠，堆叠前这批数据的标签数据是一个元组，长度为</span><code>16</code><span>；每个元素是一个</span><code>一维</code><span>的长度为</span><code>14</code><span>的张量；堆叠之后的维度变为：</span><code>(16,14)</code></p><p><img src="1-report_generation_for_M2KT.assets/image-20230827213112843.png" referrerpolicy="no-referrer" alt="image-20230827213112843"></p></li><li><p><span>最后，将结果返回到</span><code>for batch_idx, (images_id, images, reports_ids, reports_masks, labels) in enumerate(t):</code><span>语句(因此返回去的数据都是经过处理且在存储的形式和维度上都比较符合模型输入的要求的数据)；返回的时候还做了如下处理：</span></p><ol start='' ><li><p><span>将</span><code>targets</code><span>转换成长整型，将</span><code>targets_masks</code><span>转换成浮点型</span></p></li><li><p><span>将</span><code>targets</code><span>和</span><code>targets_masks</code><span>都转换成Tensor类型的张量</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230827215349649.png" referrerpolicy="no-referrer" alt="image-20230827215349649"></p></li></ol></li></ol><h5 id='31713lamrgmodelv12模型的前向计算'><span>3.1.7.1.3LAMRGModel_v12模型的前向计算</span></h5><blockquote><ol start='' ><li><p><span>调用顺序：调用</span><code>LAMRGModel_v12</code><span>的</span><code>forward</code><span>方法</span></p><ol start='' ><li><p><span>调用</span><code>_LAMRG</code><span>的</span><code>forward_iu_xray</code><span>方法，用于提取图像特征、平均池化特征、预测标签；以及对提取出来的特征的处理</span></p></li><li><p><span>基于综合了(即求平均)两张图片平均池化特征的</span><code>avg_feats</code><span>生成视觉标签</span></p></li></ol></li></ol></blockquote><h6 id='317131图像特征的提取'><span>3.1.7.1.3.1图像特征的提取</span></h6><blockquote><ol start='' ><li><p><span>在</span><code>_LAMRG</code><span>的</span><code>forward_iu_xray</code><span>方法中，调用</span><code>visual_extractor</code><span>中的</span><code>forward</code><span>方法</span></p></li><li><p><span>平均池化是对整个图像进行的</span></p></li></ol></blockquote><ol start='' ><li><p><span>首先使用</span><code>resnet101</code><span>模型对图像进行特征提取(</span><font color="red"><span>以后可以详细看一下</span><code>resnet101</code><span>模型</span></font><span>)，得到特征</span><code>patch_feats</code><span>，维度为：</span><code>(16,2048,7,7)</code></p><p><img src="1-report_generation_for_M2KT.assets/image-20230828143605974.png" referrerpolicy="no-referrer" alt="image-20230828143605974"></p><ol start='' ><li><p><code>16</code><span>：表示这个张量是一个</span><code>batch size</code><span>为</span><code>16</code><span>的张量，即有</span><code>16</code><span>张图片被同时输入到模型中进行特征提取</span></p></li><li><p><code>2048</code><span>：表示每张图片提取出来的特征向量的维度为</span><code>2048</code><span>，这个维度是由</span><code>ResNet101</code><span>模型的最后一个卷积层决定的</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230828111339206.png" referrerpolicy="no-referrer" alt="image-20230828111339206"></p></li><li><p><span>第三个维度和第四个维度表示每个特征向量的维度，即</span><code>7x7</code><span>的像素块</span></p></li></ol></li><li><p><span>接着，使用平均池化提取缩减后的特征图：</span></p><ol start='' ><li><p><code>self.avg_fnt(patch_feats)</code><span>：由于平均池化在设置的时候</span><code>kernel_size=7</code><span>，因此每次池化的区域大小是</span><code>7x7</code><span>的像素块，与</span><code>resnet101</code><span>提取的特征的大小一致，因此平均池化之后的维度就变成了</span><code>[16, 2048, 1, 1]</code></p></li><li><p><span>然后使用</span><code>squeeze</code><span>方法去除多余的维度，就变成了</span><code>[16,2048]</code></p></li><li><p><span>然后使用</span><code>reshape</code><span>函数改变维度，但其实维度上没有变化，依旧是</span><code>[16,2048]</code><span>。但是</span><code>reshape</code><span>以及前面的</span><code>squeeze</code><span>操作之后(</span><font color="red"><span>为什么要进行</span><code>reshape</code><span>，维度没变化啊？</span></font><span>)，就包含了两个梯度函数(</span><font color="red"><span>两个梯度函数有啥区别，没有</span><code>reshape</code><span>行不行？</span></font><span>)，如下图所示。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230828145905534.png" referrerpolicy="no-referrer" alt="image-20230828145905534"></p></li><li><p><span>整个过程的拆解如下图所示。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230828150204959.png" referrerpolicy="no-referrer" alt="image-20230828150204959"></p></li></ol></li><li><p><span>然后将</span><u><span>平均池化之后的特征</span></u><span>输入到分类器中，来预测图像所属的疾病标签类别。这里</span><code>labels</code><span>的维度是</span><code>[16,14]</code><span>结合论文，</span><u><span>此处预测疾病标签类别的作用是：用于后续计算标签损失</span></u><span>。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230828151006386.png" referrerpolicy="no-referrer" alt="image-20230828151006386"></p></li><li><p><span>最后，改变了</span><code>patch_feats</code><span>的维度，从</span><code>[16,2048,7,7]</code><span>变成了</span><code>[16,49,2048]</code><span>；然后返回提取的图像特征、平均池化之后的特征、根据平均池化特征预测出来的图像所属的疾病标签类别</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230828153028915.png" referrerpolicy="no-referrer" alt="image-20230828153028915"></p></li></ol><h6 id='317132特征提取后的处理'><span>3.1.7.1.3.2特征提取后的处理</span></h6><blockquote><ol start='' ><li><p><span>每条数据提取两张图像的特征</span></p></li></ol></blockquote><ol start='' ><li><p><span>首先，对这批数据中的每一条数据，对两张图片的平均池化特征</span><u><span>求平均</span></u><span>，得到综合的平均池化特征，维度是</span><code>(16, 2048)</code></p></li><li><p><span>其次，对这批数据中的每一条数据，将两张图片提取出来的特征在空间维度(即第</span><code>1</code><span>维度)进行</span><u><span>拼接</span></u><span>，得到综合特征，维度是</span><code>(16, 98, 2048)</code><span>，含义：</span><code>16</code><span>条数据，每条数据</span><code>98</code><span>个像素区域，每个区域的特征维度是</span><code>2048</code></p></li><li><p><span>最后，对这批数据中的每一条数据，将两张图片的预测标签在第</span><code>0</code><span>维度上进行平均，将平均之后的标签作为对当前患者的疾病标签的预测结果，维度是</span><code>(16, 14)</code></p></li><li><p><span>这一过程如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230828203415915.png" referrerpolicy="no-referrer" alt="image-20230828203415915"></p></li></ol><h6 id='317133视觉标签的生成'><span>3.1.7.1.3.3视觉标签的生成</span></h6><ol start='' ><li><p><span>使用综合了(即求平均)两张图片平均池化特征的</span><code>avg_feats</code><span>，经由线性层由</span><code>(16,2048)</code><span>投影到</span><code>(16,512)</code><span>的</span><code>z_img</code></p></li><li><p><span>然后使用类似的线性分类器输出疾病标签的预测结果，维度依然是</span><code>(16,14)</code></p></li><li><p><span>相较于前面直接将两个单张图片的疾病标签预测结果进行平均，这个方法更加鲁棒一点</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230828211251090.png" referrerpolicy="no-referrer" alt="image-20230828211251090"></p><h6 id='317134当前memory的获取'><span>3.1.7.1.3.4当前memory的获取</span></h6><ol start='' ><li><p><span>对当前的</span><code>self.memory</code><span>进行类型转换(包括数据类型以及设备类型），然后进行线性变换(即获取</span><code>memory</code><span>的过程)，然后进行维度扩展，扩展成</span><code>16</code><span>条数据的</span><code>memory</code><span>(扩展的过程是对原先一条数据的</span><code>memory</code><span>进行复制)</span></p><ol start='' ><li><p><span>原先</span><code>self.memory</code><span>是在cpu上的，数据类型与</span><code>images</code><span>一致，都是</span><code>float32</code><span>，转换之后，到了GPU上；</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230829105822466.png" referrerpolicy="no-referrer" alt="image-20230829105822466"></p></li><li><p><span>然后使用</span><code>self.get_mem</code><span>获取</span><code>memory</code><span>，即对</span><code>memory</code><span>进行</span><u><span>线性变换</span></u><span>，线性变换前后的维度没有变化，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230829110218052.png" referrerpolicy="no-referrer" alt="image-20230829110218052"></p></li><li><p><span>然后进行维度扩展，如下图所示，</span><code>16</code><span>条数据的</span><code>memory</code><span>是一样的</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230829151617534.png" referrerpolicy="no-referrer" alt="image-20230829151617534"></p></li></ol></li><li><p><span>对</span><code>mask</code><span>进行同样的操作：类型转换+线性变换+维度扩展，最终的维度是</span><code>(16,60,512)</code><span>。</span></p></li></ol><h6 id='317135报告文本的编码'><span>3.1.7.1.3.5报告文本的编码</span></h6><blockquote><ol start='' ><li><p><span>包括构建报告文本的掩码张量(用于报告文本编码时多头注意力计算中的掩码张量)、对报告文本进行编码、获取汇总的报告文本信息、依据获取的报告文本信息预测疾病标签类别</span></p></li></ol></blockquote><ol start='' ><li><p><span>对这批报告文本序列(维度是</span><code>[16,max_seq_length]</code><span>)构建掩码张量：维度与报告序列维度相同，也是</span><code>[16,max_seq_length]</code><span>；然后将掩码张量中每条数据的第一个掩码值设置为</span><code>1</code><span>，表示开始位置；然后给掩码张量增加维度，变成</span><code>[batch_size, 1, seq_len]</code><span>；如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230829153804069.png" referrerpolicy="no-referrer" alt="image-20230829153804069"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230829153829060.png" referrerpolicy="no-referrer" alt="image-20230829153829060"></p></li><li><p><span>对报告文本进行编码、获取汇总的报告文本信息、依据获取的报告文本信息预测疾病标签类别，如下图所示；在这个批次数据中：</span></p><ol start='' ><li><p><span>报告文本编码之后的</span><code>txt_feats</code><span>的维度是：</span><code>[16,60,512]</code></p></li><li><p><span>汇总的报告文本信息的</span><code>z_txt</code><span>的维度是：</span><code>[16,512]</code></p></li><li><p><span>预测的疾病标签的</span><code>txt_labels</code><span>的维度是：</span><code>[16,14]</code></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230829164940683.png" referrerpolicy="no-referrer" alt="image-20230829164940683"></p></li></ol><h6 id='317136对memory进行更新'><span>3.1.7.1.3.6对memory进行更新</span></h6><blockquote><ol start='' ><li><p><span>执行</span><code>self.update_memory</code><span>之后将依次调用：</span><code>MHA_FF</code><span>类的</span><code>forward</code><span>方法</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><code>SublayerConnection</code><span>类的</span><code>forward</code><span>方法</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><code>MultiHeadedAttention</code><span>类的</span><code>forward</code><span>方法</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><code>attention</code><span>方法</span></p></li><li><p><span>另外，虽然通过</span><code>self.update_memory(memory, txt_feats, mask)</code><span>语句将</span><code>memory</code><span>的掩码张量</span><code>mask</code><span>张量传入了，但是在</span><code>MHA_FF</code><span>类的</span><code>forward</code><span>方法中，执行</span><code>self.self_attn(x, feats, feats)</code><span>时并没有继续传入</span><code>mask</code><span>，因此这里</span><code>memory</code><span>的</span><code>mask</code><span>张量没有派上用场。</span></p></li></ol></blockquote><ol start='' ><li><p><span>进入</span><code>MHA_FF</code><span>类的</span><code>forward</code><span>方法之后，将会进入多头注意力机制层，这里</span><code>query</code><span>张量是记忆矩阵</span><code>memory</code><span>，</span><code>key</code><span>和</span><code>value</code><span>张量都是文本特征，</span><u><span>与论文中的图示相符合</span></u><span>；如下图所示</span></p><ol start='' ><li><p><span>这里发现：因为需要更新的是</span><code>memory</code><span>，这里就把</span><code>memory</code><span>作为了查询</span><code>query</code><span>张量(</span><font color="red"><span>后续还需要深度理解一下注意力机制三个量的具体含义</span></font><span>)</span></p></li><li><p><code>memory</code><span>更新的理解：</span><u><span>这里的知识库更新，是让知识库记忆矩阵去注意新的一批数据中的报告文本的特征</span></u><span>。</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230829200635341.png" alt="image-20230829200635341" style="zoom:50%;" /></p><p><img src="1-report_generation_for_M2KT.assets/image-20230829200716362.png" alt="image-20230829200716362" style="zoom:50%;" /></p></li><li><p><span>经过多头注意力层之后，得到更新了的</span><code>memory</code><span>。更新前后的维度不变，都是</span><code>[batch_size, num_slots, d_model]</code><span>，这里是</span><code>[16,60,512]</code></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230829201629853.png" referrerpolicy="no-referrer" alt="image-20230829201629853"></p><h6 id='317136-visual-knowledge-attention'><span>3.1.7.1.3.6 visual-knowledge attention</span></h6><blockquote><ol start='' ><li><p><span>先对标签嵌入进行线性变换，然后与</span><code>memory</code><span>一起执行注意力层，然后将之前提取的视觉特征与经过attention的标签嵌入连接起来，得到所谓的注意过</span><code>memory</code><span>的视觉特征</span></p></li><li><p><span>最后可以把标签嵌入和图像特征连接起来作为注意了知识库的视觉特征，是因为这里的标签嵌入是由视觉特征线性变换而来，本质上还是视觉特征。</span></p></li></ol></blockquote><ol start='' ><li><p><span>对标签嵌入进行线性变换，维度从</span><code>vis_labels</code><span>的</span><code>[16,14]</code><span>变成</span><code>emb_labels</code><span>的</span><code>[16,14,512]</code></p><p><img src="1-report_generation_for_M2KT.assets/image-20230830155018243.png" referrerpolicy="no-referrer" alt="image-20230830155018243"></p></li><li><p><span>然后调用</span><code>self.select_prior</code><span>方法(本质上是一个多头注意力层</span><code>MHA_FF</code><span>)，将当前的</span><code>memory</code><span>与标签嵌入做注意力操作，得到注意过知识库(记忆矩阵)的标签嵌入；维度保持不变，从</span><code>emb_labels</code><span>的</span><code>[16,14,512]</code><span>到</span><code>prior</code><span>的</span><code>[16,14,512]</code></p><ol start='' ><li><p><span>与更新</span><code>memory</code><span>时的注意力类似，这里是要让标签嵌入去注意记忆矩阵，因此标签嵌入</span><code>emb_labels</code><span>就作为了查询张量</span><code>query</code></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230830155536156.png" referrerpolicy="no-referrer" alt="image-20230830155536156"></p></li><li><p><span>最后，将前面提取的图像特征与这里注意过知识库的标签嵌入</span><code>prior</code><span>连接起来，得到所谓的注意过</span><code>memory</code><span>的视觉特征，作为最终的图像特征；先对</span><code>prior</code><span>进行线性变换是为了将</span><code>prior</code><span>的最后一个维度变成和</span><code>att_feats</code><span>一样，即将</span><code>prior</code><span>的维度变为</span><code>[16,14,2048]</code></p><ol start='' ><li><p><span>连接前，</span><code>att_feats</code><span>的维度是</span><code>[16,98,2048]</code><span>；在第一个维度进行连接，连接后维度变成</span><code>[16, 98+14, 2048]</code></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230830160253393.png" referrerpolicy="no-referrer" alt="image-20230830160253393"></p></li></ol><h6 id='317137使用encoderdecoder计算输出'><span>3.1.7.1.3.7使用encoder_decoder计算输出</span></h6><blockquote><ol start='' ><li><p><span>调用过程：一般来说，pytorch中，通过对象名称直接传入参数，会调用该对象中的</span><code>forward</code><span>方法；这里的</span><code>encoder_decoder</code><span>对象是一个</span><code>TransformerModel</code><span>类，因此也是这种逻辑</span></p></li><li><p><code>TransformerModel</code><span>类继承自</span><code>AttModel</code><span>，进一步继承自</span><code>CaptionModel</code><span>，而</span><code>CaptionModel</code><span>中有</span><code>forward</code><span>方法，因此首先会进入</span><code>CaptionModel</code><span>的</span><code>forward</code><span>方法，如下图所示；由于这里的</span><code>forward</code><span>方法中有一个</span><code>**kwargs</code><span>可以接收关键字参数，因此</span><code>output = self.encoder_decoder(avg_feats, att_feats, targets, mode=&#39;forward&#39;)</code><span>中增加</span><code>mode=&#39;forward&#39;</code><span>也就不奇怪了</span></p><ol start='' ><li><p><span>通过</span><code>mode = kwargs.get(&#39;mode&#39;, &#39;forward&#39;)</code><span>获取</span><code>mode</code><span>关键字的值，然后通过调用对应的函数，这里就是去调用</span><code>TransformerModel</code><span>类的</span><code>_forward</code><span>方法</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230830171935929.png" referrerpolicy="no-referrer" alt="image-20230830171935929"></p></li><li><p><span>因此，总的调用过程为：</span><code>TransformerModel</code><span>类</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><code>CaptionModel</code><span>中的</span><code>forward</code><span>方法</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><code>TransformerModel</code><span>类的</span><code>_forward</code><span>方法</span></p></li></ol></blockquote><ol start='' ><li><p><span>编码器解码器模块是一个transformer模型(创建过程详见</span><a href='#31312-encoderdecoder的创建'><span>3.1.3.1.2 encoder_decoder的创建</span></a><span>)，结构如下：</span></p><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python" style="break-inside: unset;"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">TransformerModel</span>(</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">  (<span class="cm-variable">att_embed</span>): <span class="cm-variable">Sequential</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  (<span class="cm-number">0</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">2048</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  (<span class="cm-number">1</span>): <span class="cm-variable">Dropout</span>(<span class="cm-variable">p</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">inplace</span><span class="cm-operator">=</span><span class="cm-keyword">False</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">  (<span class="cm-variable">logit</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">761</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">  (<span class="cm-variable">model</span>): <span class="cm-variable">EncoderDecoder</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  (<span class="cm-variable">encoder</span>): <span class="cm-variable">Encoder</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;  (<span class="cm-variable">layers</span>): <span class="cm-variable">ModuleList</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; <span class="cm-comment"># ...编码器层有3个，此处只显示最后一个编码器层...</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  (<span class="cm-number">2</span>): <span class="cm-variable">EncoderLayer</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">self_attn</span>): <span class="cm-variable">MultiHeadedAttention</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">linears</span>): <span class="cm-variable">ModuleList</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">0</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">1</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">2</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">3</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">dropout</span>): <span class="cm-variable">Dropout</span>(<span class="cm-variable">p</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">inplace</span><span class="cm-operator">=</span><span class="cm-keyword">False</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">feed_forward</span>): <span class="cm-variable">PositionwiseFeedForward</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">w_1</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">w_2</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">dropout</span>): <span class="cm-variable">Dropout</span>(<span class="cm-variable">p</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">inplace</span><span class="cm-operator">=</span><span class="cm-keyword">False</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">sublayer</span>): <span class="cm-variable">ModuleList</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">0</span>): <span class="cm-variable">SublayerConnection</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">norm</span>): <span class="cm-variable">LayerNorm</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">dropout</span>): <span class="cm-variable">Dropout</span>(<span class="cm-variable">p</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">inplace</span><span class="cm-operator">=</span><span class="cm-keyword">False</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">1</span>): <span class="cm-variable">SublayerConnection</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">norm</span>): <span class="cm-variable">LayerNorm</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">dropout</span>): <span class="cm-variable">Dropout</span>(<span class="cm-variable">p</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">inplace</span><span class="cm-operator">=</span><span class="cm-keyword">False</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;  (<span class="cm-variable">norm</span>): <span class="cm-variable">LayerNorm</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  (<span class="cm-variable">decoder</span>): <span class="cm-variable">Decoder</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;  (<span class="cm-variable">layers</span>): <span class="cm-variable">ModuleList</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-comment"># ...解码器层有3个，此处只显示最后一个解码器层...</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-comment"># 解码器依然是标准的transformer解码器，即包含两个多头注意力层，一个是目标序列的自注意力、一个是编码器堆栈注意力</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  (<span class="cm-number">2</span>): <span class="cm-variable">DecoderLayer</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">self_attn</span>): <span class="cm-variable">MultiHeadedAttention</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">linears</span>): <span class="cm-variable">ModuleList</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">0</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">1</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">2</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">3</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">dropout</span>): <span class="cm-variable">Dropout</span>(<span class="cm-variable">p</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">inplace</span><span class="cm-operator">=</span><span class="cm-keyword">False</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">src_attn</span>): <span class="cm-variable">MultiHeadedAttention</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">linears</span>): <span class="cm-variable">ModuleList</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">0</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">1</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">2</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">3</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">dropout</span>): <span class="cm-variable">Dropout</span>(<span class="cm-variable">p</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">inplace</span><span class="cm-operator">=</span><span class="cm-keyword">False</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">feed_forward</span>): <span class="cm-variable">PositionwiseFeedForward</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">w_1</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">w_2</span>): <span class="cm-variable">Linear</span>(<span class="cm-variable">in_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">out_features</span><span class="cm-operator">=</span><span class="cm-number">512</span>, <span class="cm-variable">bias</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">dropout</span>): <span class="cm-variable">Dropout</span>(<span class="cm-variable">p</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">inplace</span><span class="cm-operator">=</span><span class="cm-keyword">False</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">sublayer</span>): <span class="cm-variable">ModuleList</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">0</span>): <span class="cm-variable">SublayerConnection</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">norm</span>): <span class="cm-variable">LayerNorm</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">dropout</span>): <span class="cm-variable">Dropout</span>(<span class="cm-variable">p</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">inplace</span><span class="cm-operator">=</span><span class="cm-keyword">False</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">1</span>): <span class="cm-variable">SublayerConnection</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">norm</span>): <span class="cm-variable">LayerNorm</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">dropout</span>): <span class="cm-variable">Dropout</span>(<span class="cm-variable">p</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">inplace</span><span class="cm-operator">=</span><span class="cm-keyword">False</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-number">2</span>): <span class="cm-variable">SublayerConnection</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">norm</span>): <span class="cm-variable">LayerNorm</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">dropout</span>): <span class="cm-variable">Dropout</span>(<span class="cm-variable">p</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">inplace</span><span class="cm-operator">=</span><span class="cm-keyword">False</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;  (<span class="cm-variable">norm</span>): <span class="cm-variable">LayerNorm</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment"># 只有一个对报告文本进行嵌入操作的embedding层</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment"># 图像没有设置embedding，因为在前面图像特征提取的时候就已经操作过了</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  (<span class="cm-variable">tgt_embed</span>): <span class="cm-variable">Sequential</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;  (<span class="cm-number">0</span>): <span class="cm-variable">Embeddings</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">lut</span>): <span class="cm-variable">Embedding</span>(<span class="cm-number">761</span>, <span class="cm-number">512</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;  (<span class="cm-number">1</span>): <span class="cm-variable">PositionalEncoding</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">dropout</span>): <span class="cm-variable">Dropout</span>(<span class="cm-variable">p</span><span class="cm-operator">=</span><span class="cm-number">0.1</span>, <span class="cm-variable">inplace</span><span class="cm-operator">=</span><span class="cm-keyword">False</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">  )</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">)</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 2234px;"></div><div class="CodeMirror-gutters" style="display: none; height: 2234px;"></div></div></div></pre></li><li><p><span>进入</span><code>TransformerModel</code><span>类的</span><code>_forward</code><span>方法之后，会先调用</span><code>_prepare_feature_forward</code><span>方法构建新的视觉特征的掩码张量</span><code>att_masks</code><span>、报告文本序列的掩码张量</span><code>seq_mask</code><span>、视觉特征</span><code>att_feats</code><span>（在原先的基础之上），具体如下(</span><a id="anchor1"><span>anchor1</span></a><span>)：</span></p><ol start='' ><li><p><span>针对视觉特征：对视觉特征进行embedding操作(本质上是一个线性层+dropout层)，维度发生了变化，从</span><code>[batch_size, 98+14, 2048]</code><span>变为</span><code>[batch_size, 98+14, 512]</code></p><p><img src="1-report_generation_for_M2KT.assets/image-20230830221530120.png" referrerpolicy="no-referrer" alt="image-20230830221530120"></p></li><li><p><span>针对视觉特征的掩码张量：由于传入时</span><code>att_masks</code><span>总是</span><code>None</code><span>，因此这里重新构建了</span><code>att_masks</code><span>，维度是</span><code>[batch_size, 98+14]</code><span>，且所有元素都设置为</span><code>1</code><span>，表示所有像素都是有效的，都会考虑进来；然后再增加一个维度，变为</span><code>[batch_size, 1 , 98+14]</code></p><p><img src="1-report_generation_for_M2KT.assets/image-20230830221925901.png" referrerpolicy="no-referrer" alt="image-20230830221925901"></p></li><li><p><span>针对文本序列的掩码张量：之前在对报告文本进行编码时就构建过一次掩码张量(见</span><a href='#317135报告文本的编码'><span>3.1.7.1.3.5报告文本的编码</span></a><span>)；</span></p><ol start='' ><li><p><span>由于这里在transformer的解码时需要用到，因此再一次进行掩码张量的构建，构建过程有所不同，不同的地方在下图所示的位置(因为这个掩码张量需要用于解码过程，因此还需要遮蔽后续位置)</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230830222259572.png" referrerpolicy="no-referrer" alt="image-20230830222259572"></p></li><li><p><span>综合考虑报告文本的有效元素以及解码时需要遮蔽的位置之后，得到最终的</span><code>seq_mask</code><span>；整个过程的维度变化为：</span><code>[batch_size, max_seq_length]</code><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><code>[batch_size, 1, max_seq_length]</code><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><code>[batch_size, max_seq_length, max_seq_length]</code><span>。本例的最终维度如下图所示。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230830223036964.png" referrerpolicy="no-referrer" alt="image-20230830223036964"></p></li></ol></li><li><p><span>然后是针对一张图片对应多个文本序列的情况的处理(</span><font color="blue"><span>这种情况在目前的方法中不存在，但是比如要考虑患者不同时期的报告的时候可能就需要了，或者考虑患者同一时期不同类型的报告的时候</span></font><span>)</span></p></li><li><p><span>最终，返回结果，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230831120330045.png" referrerpolicy="no-referrer" alt="image-20230831120330045"></p></li></ol></li><li><p><span>接下来进入transformer模型，进行编码和解码；输入的参数中，视觉特征</span><code>att_feats</code><span>对应模型中的</span><code>src</code><span>，报告文本序列对应模型中的</span><code>tgt</code><span>，</span><code>att_masks</code><span>、</span><code>seq_mask</code><span>分别对应模型中的</span><code>src_mask</code><span>、</span><code>tgt_mask</code></p><ol start='' ><li><p><span>编码时(</span><a id="anchor2"><span>anchor2</span></a><span>)：</span></p><ol start='' ><li><p><span>由于图片已经提取了特征了，因此这里的</span><code>src_embed</code><span>是一个不进行任何操作的匿名函数</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230831122937061.png" referrerpolicy="no-referrer" alt="image-20230831122937061"></p></li><li><p><span>为了便于注意力的计算（因为计算评分函数时</span><code>scores</code><span>的维度将变成</span><code>(16,8,112,112)</code><span>），</span><code>src_mask</code><span>增加了一个维度，从</span><code>(16,1,112)</code><span>变成了</span><code>(16,1,1,112)</code><span>；另外，</span><code>src_mask</code><span>全是</span><code>1</code><span>，表示报告文本序列的所有元素都考虑进来</span></p></li><li><p><span>计算注意力时，由于是编码，因此</span><code>q、k、v</code><span>都是视觉特征，维度是</span><code>(16,112,512)</code><span>；为了进行多头注意力，变换之后的</span><code>q、k、v</code><span>的维度就变成了</span><code>(16,8,112,64)</code><span>；计算完多头注意力之后，特征维度就又变回了</span><code>(16,112,512)</code></p></li></ol></li><li><p><span>解码时</span><a name="anchor5"><span>Anchor5</span></a><span>：</span></p><ol start='' ><li><p><span>首先使用</span><code>self.tgt_embed</code><span>对目标序列(报告文本序列)进行embedding操作，从而使</span><code>tgt</code><span>的维度从</span><code>(16,60)</code><span>变为</span><code>(16,60,512)</code></p></li><li><p><span>其次进行目标序列的自注意力计算；为了便于注意力的计算（因为计算评分函数时</span><code>scores</code><span>的维度将变成</span><code>(16,8,60,60)</code><span>），</span><code>tgt_mask</code><span>增加了一个维度，从</span><code>(16,60,60)</code><span>变成了</span><code>(16,1,60,60)</code><span>；此时的</span><code>tgt_mask</code><span>是经过</span><code>subsequent_mask</code><span>的掩码张量，不再是像视觉特征的掩码张量那样，全为</span><code>1</code><span>了；计算完自注意力之后，目标序列的特征维度变为</span><code>(16,60,512)</code></p></li><li><p><span>接下来进行编码器堆栈注意力；注意这里使用目标序列(报告文本序列)作为</span><code>query</code><span>，和之前类似，可以理解为让目标序列关注编码器过来的源序列；掩码张量使用的是源序列，即视觉特征的掩码张量，因为最后使用</span><code>p_attn</code><span>和</span><code>value</code><span>相乘，而</span><code>value</code><span>本质上就是源序列(视觉特征)；</span></p><ol start='' ><li><p><span>此处</span><code>x</code><span>，即报告文本序列的维度是</span><code>(16,60,512)</code><span>；</span><code>m</code><span>，即视觉特征经过编码器编码的结果，维度是</span><code>(16,112,512)</code><span>；掩码张量的维度是</span><code>(16,1,112)</code><span>，为全</span><code>1</code><span>的张量</span></p></li><li><p><u><span>由于视觉特征与文本序列特征不同，构建文本特征的掩码张量的时候是基于subsequent_mask的思想，因此掩码张量最终是一个方阵；而视觉特征的掩码张量不是这个思想，并且本文也是将视觉特征都考虑进来</span></u><span>。</span></p></li></ol></li></ol></li><li><p><span>最终，得到transformer模型的输出，维度是</span><code>(16,60,512)</code></p></li><li><p><span>最后，对解码器的输出结果进行线性变换，让维度从</span><code>[batch_size, max_seq_length, 512]</code><span>变成</span><code>[batch_size, max_seq_length, vocab_size+1]</code><span>，然后进行对数softmax，转化成概率，然后return。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230901091257396.png" referrerpolicy="no-referrer" alt="image-20230901091257396"></p><p><span>下图是转化成概率之后返回的输出</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230901145239795.png" referrerpolicy="no-referrer" alt="image-20230901145239795"></p></li></ol></li></ol><h6 id='317138返回前向计算结果'><span>3.1.7.1.3.8返回前向计算结果</span></h6><ol start='' ><li><p><span>返回以下的量：</span></p><ol start='' ><li><p><code>output</code><span>：是经过对数softmax的解码器的输出结果，维度是</span><code>[batch_size, max_seq_length, vocab_size+1]</code><span>，这里为</span><code>[16,60,761]</code></p></li><li><p><code>vis_labels</code><span>：两张图片的平均池化特征，经过分类器预测之后的标签结果，维度是</span><code>[16,14]</code></p></li><li><p><code>txt_labels</code><span>：依据报告文本信息预测的疾病标签类别，维度也是</span><code>[16,14]</code></p></li><li><p><code>z_img</code><span>：对综合了(即求平均)两张图片的平均池化特征进行线性变换之后的结果，维度是</span><code>[16,512]</code></p></li><li><p><code>z_txt</code><span>：表示文本特征的汇总，即开始符这个位置的特征，维度是</span><code>[batch_size, d_model]</code></p></li></ol></li><li><p><span>计算结果返回至</span><code>Trainer</code><span>类实现的</span><code>_train_epoch</code><span>方法，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230904110822481.png" referrerpolicy="no-referrer" alt="image-20230904110822481"></p></li></ol><h4 id='3172train方法的后续内容'><span>3.1.7.2</span><code>train</code><span>方法的后续内容</span></h4><p><a name="anchor8"><span>Anchor8</span></a><span> </span></p><ol start='' ><li><p><span>回到</span><code>BaseTrainer</code><span>的</span><code>train</code><span>方法之后，将</span><code>epoch</code><span>数据也存到日志字典中，然后执行</span><code>self._record_best(log)</code><span>来更新最佳的结果：</span></p><ol start='' ><li><p><span>如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230912143655892.png" referrerpolicy="no-referrer" alt="image-20230912143655892"></p></li><li><p><span>更新的过程见</span><a href="#anchor9"><span>3.1.7.2.1更新最佳结果</span></a><span>。</span></p></li></ol></li><li><p><span>接着执行</span><code>self._print_epoch(log)</code><span>来打印相关信息，具体见</span><a href="#anchor10"><span>3.1.7.2.2打印相关信息</span></a><span>。</span></p></li><li><p><span>接着，判断一下指标有没有变得更好：</span></p><ol start='' ><li><p><span>这里和</span><u><span>3.1.7.2.1更新最佳结果</span></u><span>没啥区别，唯一的区别是这里只记录了验证集的</span><code>BLEU_4</code><span>指标值，而</span><code>_record_best(log)</code><span>记录了验证集和测试集的所有指标值</span></p></li><li><p><span>如果与最好的相比指标值更好了，那就更新，否则的话，就</span><code>not_improved_count += 1</code></p></li><li><p><span>因此，</span><code>not_improved_count</code><span> 记录模型在多少个epoch中性能指标没有得到改善，如果得到改善该变量会重置为</span><code>0</code><span>，</span><u><span>用于判断模型训练什么时候可以停止</span></u><span>，如果几个epoch内还没有改进的话，就停止迭代</span></p></li><li><p><span>如果达到预设的保存检查点的周期，则会保存一次检查点，这里默认每一个epoch都会保存。关于检查点的保存详见</span><a href="#anchor11"><span>3.1.7.2.3保存检查点</span></a><span>。</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230913111848584.png" referrerpolicy="no-referrer" alt="image-20230913111848584"></p></li><li><p><span>最后，所有epoch结束，打印最好的结果，同时保存最好的结果到文件</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230913115020607.png" referrerpolicy="no-referrer" alt="image-20230913115020607"></p></li></ol><h5 id='31721更新最佳结果'><span>3.1.7.2.1更新最佳结果</span></h5><p><a name="anchor9"><span>Anchor9</span></a><span> </span></p><blockquote><ol start='' ><li><p><span>初始的最佳记录只有BLEU_4这一个指标，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230912144704823.png" referrerpolicy="no-referrer" alt="image-20230912144704823"></p></li><li><p><span>更新之后，最佳记录中就不止有BLEU_4指标的值了</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230912144853574.png" referrerpolicy="no-referrer" alt="image-20230912144853574"></p></li><li><p><span>将更新验证集和测试集的最佳结果</span></p></li></ol></blockquote><ol start='' ><li><p><span>整个过程如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230912145231656.png" referrerpolicy="no-referrer" alt="image-20230912145231656"></p></li></ol><h5 id='31722打印相关信息'><span>3.1.7.2.2打印相关信息</span></h5><p><a name="anchor10"><span>Anchor10</span></a><span> </span></p><ol start='' ><li><p><span>包含的内容有：</span></p><ol start='' ><li><p><span>当前的训练轮次(</span><code>epoch</code><span>)以及检查点目录(</span><code>checkpoint_dir</code><span>)</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230912151448848.png" referrerpolicy="no-referrer" alt="image-20230912151448848"></p></li><li><p><span>将验证集和测试集结果加入到日志中，并在控制台打印出来</span></p></li><li><p><span>添加验证集和测试集的评价指标及其对应的周期数到tensorboard中</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230912151521110.png" referrerpolicy="no-referrer" alt="image-20230912151521110"></p></li><li><p><span>此处打印信息有点问题，不管是在什么情况下调用这个函数，都会将验证集和测试集同时输出，因此在最后执行</span><code>self._print_best()</code><span>的时候，会出现“验证集中也输出了测试集的结果，测试集中也输出了验证集的结果”，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230913212452048.png" referrerpolicy="no-referrer" alt="image-20230913212452048"></p></li></ol><h5 id='31723保存检查点'><span>3.1.7.2.3保存检查点</span></h5><p><a name="anchor11"><span>Anchor11</span></a><span> </span></p><ol start='' ><li><p><span>有两处会进行检查点的保存：</span></p><ol start='' ><li><p><span>训练过程中会按照设定的保存周期进行保存操作：达到设定的保存周期时，保存当前epoch的检查点，肯定会保存当前epoch的检查点(要么是interrupt要么是current)；如果这一个epoch的验证集指标更好，则还会保存截至目前的最佳检查点</span></p></li><li><p><span>当被人为键盘打断时，会保存当时的检查点信息。</span><code>_save_checkpoint</code><span>函数位于</span><code>BaseTrainer</code><span>类中</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230913113626015.png" referrerpolicy="no-referrer" alt="image-20230913113626015"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230913113731804.png" referrerpolicy="no-referrer" alt="image-20230913113731804"></p></li></ol><h2 id='32分析'><span>3.2分析</span></h2><h3 id='321关于论文中的标签损失'><span>3.2.1关于论文中的标签损失</span></h3><ol start='' ><li><p><span>在代码中，提取图像特征之后，使用平均池化获取经过平均池化的特征，然后将该特征输入到分类器中，从而预测出当前单张图像的疾病标签预测结果，然后将两张图像的疾病标签预测结果取平均值，作为当前患者的最终疾病标签预测结果。</span></p></li><li><p><span>但是，在</span><code>forward_iu_xray</code><span>执行完毕返回之后，并没有接收返回的</span><code>out_labels</code><span>，而是在之后又重新预测了标签，这次预测标签的过程和</span><code>forward_iu_xray</code><span>中预测标签的过程有所不同。但这次预测的标签结果应该是用于后续和真实的标签做对比，计算损失，是视觉-标签对齐的具体实现。</span></p></li><li><p><span>此外，在对报告文本进行编码的时候，还用编码后的结果去预测了疾病标签类别</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230829164140246.png" referrerpolicy="no-referrer" alt="image-20230829164140246"></p></li></ol><h2 id='33报错信息'><span>3.3报错信息</span></h2><h3 id='331找不到指定模块'><span>3.3.1找不到指定模块</span></h3><ol start='' ><li><p><span>报错信息如下图：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230808175306391.png" referrerpolicy="no-referrer" alt="image-20230808175306391"></p></li><li><p><span>经查，我这里应该是同时装了</span><code>PIL</code><span>包以及</span><code>Pillow</code><span>包，</span><a href='https://pillow.readthedocs.io/en/latest/installation.html'><span>官网</span></a><span>说这两个包不能同时存在于同一个环境中，因此：</span></p><ol start='' ><li><p><span>先使用</span><code>pip uninstall Pillow</code><span>将本环境中存在的</span><code>Pillow</code><span>删干净（貌似通过这个命令顺带把</span><code>PIL</code><span>也给删掉了）</span></p></li><li><p><span>然后使用</span><code>pip install Pillow</code><span>安装版本合适的</span><code>Pillow</code></p></li><li><p><span>注意：如果上述方法还是没有解决问题，请看一下是否是</span><code>PIL</code><span>和</span><code>Pillow</code><span>包并存了</span></p></li></ol></li><li><p><span>如果间断的出现找不到这里的报错的话，用</span><a href='https://blog.csdn.net/weixin_42433809/article/details/128994008?spm=1001.2014.3001.5501'><span>这篇文章</span></a><span>说的方法彻底删除</span><code>pillow</code><span>然后再安装。(目前总是断断续续的报这个错误，还没找到更好的解决办法)</span></p></li></ol><h3 id='332编码错误'><span>3.3.2编码错误</span></h3><ol start='' ><li><p><span>在Windows机器上运行会报这个错误：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230809170217127.png" referrerpolicy="no-referrer" alt="image-20230809170217127"></p></li><li><p><span>经查，有一个解决方案可以动态的判断所打开的文件的编码方式（</span><a href='https://blog.csdn.net/mighty13/article/details/107132272'><span>详见这篇文章</span></a><span>），按照里面的方法做了之后，又报下图的错误：</span></p><ol start='' ><li><p><span>通过debug，发现使用</span><a href='https://blog.csdn.net/mighty13/article/details/107132272'><span>详见这篇文章</span></a><span>将待打开的yaml文件的格式判断成了</span><code>ASCII</code><span>格式，可能判断错了。</span></p></li><li><p><span>通过翻看评论区，说打开文件的时候设置成</span><code>utf-8</code><span>就不报错了，尝试之后，确实不报错了。如下面第二张图所示。</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230809170407916.png" referrerpolicy="no-referrer" alt="image-20230809170407916"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230809170726787.png" referrerpolicy="no-referrer" alt="image-20230809170726787"></p></li></ol><h3 id='333其他报错信息'><span>3.3.3其他报错信息</span></h3><ol start='' ><li><p><span>找不到</span><code>pandas</code><span>，直接安装，如下图</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230808204605690.png" referrerpolicy="no-referrer" alt="image-20230808204605690"></p></li><li><p><span>找不到</span><code>pycocoevalcap</code><span>包，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230808221712961.png" referrerpolicy="no-referrer" alt="image-20230808221712961"></p><ol start='' ><li><p><span>使用</span><code>pip install pycocoevalcap</code><span>进行安装，但是安装过程报错，需要安装Microsoft Visual C++ 14.0，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230808221812519.png" referrerpolicy="no-referrer" alt="image-20230808221812519"></p></li><li><p><span>按照</span><a href='https://blog.csdn.net/colleges/article/details/123769410'><span>这篇文章</span></a><span>所描述的，安装Visual C++ build tools</span></p></li><li><p><span>但是还是有问题，按照</span><a href='https://blog.csdn.net/weixin_40922744/article/details/103687153'><span>这篇文章</span></a><span>所述，还需要安装</span><code>Cython</code><span>，安装完</span><code>Cython</code><span>之后，再执行</span><code>pip install pycocoevalcap</code><span>，就不报错了</span></p></li></ol></li><li><p><span>通过点击包的名称让pycharm帮我安装</span><code>scipy</code><span>、</span><code>tqdm</code><span>、</span><code>tensorboardX</code><span>，</span><code>ipdb</code><span>如下图所示</span></p><ol start='' ><li><p><code>ipdb</code><span>是一个调试器，关于</span><code>ipdb</code><span>，详细介绍见这里：</span><a href='https://zhuanlan.zhihu.com/p/365255205' target='_blank' class='url'>https://zhuanlan.zhihu.com/p/365255205</a><span>。使用</span><code>pip install ipdb</code><span>安装</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230809115217984.png" referrerpolicy="no-referrer" alt="image-20230809115217984"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230809150114032.png" referrerpolicy="no-referrer" alt="image-20230809150114032"></p></li><li><p><span>由于</span><code>yacs</code><span>的版本问题，导致下图所示的报错：</span></p><ol start='' ><li><p><span>原先安装的</span><code>yacs</code><span>版本为</span><code>0.1.6</code><span>，报了下图的错误</span></p></li><li><p><a href='https://blog.csdn.net/bb_sy_w/article/details/122213038'><span>查阅资料</span></a><span>，说是版本问题，因此先使用</span><code>pip uninstall yacs</code><span>卸载掉该版本，然后</span><code>pip install yacs</code><span>默认安装</span><code>0.1.8</code><span>版本的</span><code>yacs</code><span>。问题消失。</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230810103221815.png" referrerpolicy="no-referrer" alt="image-20230810103221815"></p></li></ol><p>&nbsp;</p><h2 id='4补充'><span>4补充</span></h2><h2 id='41损失计算过程'><span>4.1损失计算过程</span></h2><blockquote><p><span>使用</span><code>compute_loss</code><span>函数进行损失的计算</span></p></blockquote><ol start='' ><li><p><code>compute_loss</code><span>的输入参数如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230905152651636-4247192.png" referrerpolicy="no-referrer" alt="image-20230905152651636"></p><p><span>对应的调用</span><code>compute_loss</code><span>时传入的参数如下图所示(传入的</span><code>txt_label</code><span>并没有使用)：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230905152753133-4247192.png" referrerpolicy="no-referrer" alt="image-20230905152753133"></p></li><li><p><span>然后创建一个损失的对象，是</span><code>LanguageModelCriterion</code><span>类的实例，该类继承自</span><code>nn.Module</code><span>，初始化的时候没有额外的操作，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230905153250316-4247192.png" referrerpolicy="no-referrer" alt="image-20230905153250316"></p></li></ol><h3 id='411损失计算'><span>4.1.1损失计算</span></h3><h4 id='4111计算交叉熵损失'><span>4.1.1.1计算交叉熵损失</span></h4><blockquote><ol start='' ><li><p><span>执行</span><code>loss = criterion(output[:, :-1], reports_ids[:, 1:], reports_masks[:, 1:]).mean()</code><span>语句，调用</span><code>LanguageModelCriterion</code><span>类的</span><code>forward</code><span>方法</span></p></li><li><p><code>forward</code><span>方法中计算的损失对应于论文中的Textual–Textual Alignment，即真实报告和生成的报告之间的对齐，也即交叉熵损失</span></p></li></ol></blockquote><ol start='' ><li><p><span>用到的参数或者说张量：</span></p><ol start='' ><li><p><code>input</code><span>形参：实际传入的是</span><code>output[:, :-1]</code><span>，维度是</span><code>(16,59,761)</code><span>，</span><code>output</code><span>维度是</span><code>(16,60,761)</code><span>，去掉的是结束符所在的位置(和transformer里面的损失计算是对应上的)</span></p><ol start='' ><li><p><font color="red"><span>模型的预测输出序列</span><code>output</code><span>的第二个维度，即长度为</span><code>60</code><span>的维度，该维度上第一个元素是对真实报告文本中第一个词的预测(结合transformer中下一个词预测这种思想)，而该维度上最后一个元素应该是对报告文本的结束符的预测；因此计算交叉熵损失的时候传入的是</span><code>output[:, :-1]</code><span>而不是</span><code>output</code></font></p></li></ol></li><li><p><code>target</code><span>形参：实际传入的是</span><code>reports_ids[:, 1:]</code><span>，维度是</span><code>(16,59)</code><span>，</span><code>reports_ids</code><span>的维度是</span><code>(16,60)</code><span>，去掉了第一个元素，即开始符(和transformer里面的损失计算是对应上的)，不过还是保留了填充符和结束符</span></p><ol start='' ><li><p><font color="red"><code>reports_ids</code><span>中的第一个元素是开始符，需要将其去掉，这样第一个元素才是真实文本序列的第一个词</span></font><span>；</span></p></li></ol></li><li><p><code>mask</code><span>形参：与</span><code>target</code><span>对应，所以实际传入的是</span><code>reports_masks[:, 1:]</code><span>，维度是</span><code>(16,59)</code><span>，</span><code>reports_masks</code><span>的维度是</span><code>(16,60)</code></p></li></ol></li><li><p><span>进入</span><code>forward</code><span>函数之后，根据</span><code>input</code><span>对</span><code>target</code><span>和</span><code>mask</code><span>进行截断(如下图所示)，目的是保证这三个量在序列长度(即文本长度)上是一样的，但是在传进来的时候就已经做了处理了，已经是长度一样，都是</span><code>59</code><span>，所以这里的操作前后没有变化</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230906201955379.png" referrerpolicy="no-referrer" alt="image-20230906201955379"></p></li><li><p><span>接下来为计算交叉熵损失(</span><font color="red"><span>后面详细看一下交叉熵损失的原理</span></font><span>)做准备：交叉熵损失就是模型输出转化成概率之后的和的平均，如下图所示是论文中交叉熵的计算公式：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230906202105137.png" alt="image-20230906202105137" style="zoom:50%;" /></p><ol start='' ><li><p><span>该公式理解为：在知道视觉特征以及记忆矩阵之后模型预测的输出结果，转化成概率(在代码中的实现就是进行了对数softmax)之后，把每个位置的预测概率求和然后求平均，因为已经是对数softmax了，所以就不用再求对数了</span></p></li><li><p><span>对应的处理代码为：</span><code>output = -input.gather(2, target.long().unsqueeze(2)).squeeze(2) * mask</code></p><ol start='' ><li><p><code>target.long().unsqueeze(2)</code><span>：将</span><code>target</code><span>变成长整型(</span><code>int64</code><span>)，便于计算，然后扩展维度，使得</span><code>target</code><span>的维度从</span><code>[16,59]</code><span>变成</span><code>[16,59,1]</code></p></li><li><p><code>input.gather(2, target.long().unsqueeze(2))</code><span>：</span></p><ol start='' ><li><p><code>gather(dim,indexs)</code><span>函数：在</span><code>dim</code><span>维度(</span><code>dim</code><span>从</span><code>0</code><span>开始)上，按照</span><code>indexs</code><span>所给的坐标选择元素，返回一个和</span><code>indexs</code><span>维度相同大小的tensor</span></p></li><li><p><span>因此这里是在最后一个维度(</span><code>dim=2</code><span>)上按照</span><code>target</code><span>最后一个维度给出的索引(即词表的索引)从</span><code>input</code><span>中拿到对应位置的元素，本质上就是从模型输出的概率序列中获取真实token的预测概率值</span></p></li><li><p><span>返回的Tensor的维度是</span><code>[16,59,1]</code></p></li></ol></li><li><p><span>然后使用</span><code>squeeze(2)</code><span>把最后一个维度删掉，变回</span><code>[16,59]</code><span>，其中的每个元素就代表模型对真实token的预测概率</span></p></li><li><p><span>然后乘上</span><code>mask</code><span>，将填充符对应的概率置为</span><code>0</code><span>，这样在计算损失的时候就不会把填充的位置考虑进来了</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230906203859169.png" referrerpolicy="no-referrer" alt="image-20230906203859169"></p></li><li><p><span>对应的最终交叉熵损失计算代码为</span><code>output = torch.sum(output) / torch.sum(mask)</code><span>：</span></p><ol start='' ><li><p><code>torch.sum(output)</code><span>：是对这一批数据的所有预测概率值进行求和</span></p></li><li><p><code>torch.sum(mask)</code><span>：用于求总共有多少个token；用</span><code>mask</code><span>来计算的原因是</span><code>mask</code><span>中的填充符和结束符(开始符是</span><code>1</code><span>)都是</span><code>0</code><span>，求和之后正好就没有把填充符和结束符的位置算进去</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230906204132747.png" referrerpolicy="no-referrer" alt="image-20230906204132747"></p></li></ol></li><li><p><span>如下图所示，是</span><u><span>交叉熵损失的计算结果</span></u><span>：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230906213953443.png" referrerpolicy="no-referrer" alt="image-20230906213953443"></p></li><li><p><span>语句</span><code>loss = criterion(output[:, :-1], reports_ids[:, 1:], reports_masks[:, 1:]).mean()</code><span>中的mean()函数没有改变损失的数值，因为在计算交叉熵损失函数的时候就已经平均过了：</span></p><ol start='' ><li><p><span>如下图所示，在</span><code>mean()</code><span>作用了之后，损失值没有发生变化，但是反向传播函数发生了变化，从</span><code>DivBackward0</code><span>变成了</span><code>MeanBackward0</code><span>如下图所示：</span></p><p><font color="red"><span>关于不同的梯度函数的区别，比如这里数值上没有变化，但是梯度函数变了，变化前后有影响吗？</span></font></p><p><img src="1-report_generation_for_M2KT.assets/image-20230906214932367.png" referrerpolicy="no-referrer" alt="image-20230906214932367"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230906214949176.png" referrerpolicy="no-referrer" alt="image-20230906214949176"></p></li></ol></li></ol><h4 id='4112计算标签损失'><span>4.1.1.2计算标签损失</span></h4><blockquote><ol start='' ><li><p><span>对应论文中的Visual–Label Alignment</span></p></li></ol></blockquote><ol start='' ><li><p><span>使用的是二分类交叉熵损失(</span><font color="red"><span>后续可以详细看一下</span></font><span>)，即结合了二进制交叉熵损失(Binary Cross Entropy Loss)和逻辑斯蒂激活函数(Logit function)，公式如下：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230907194527792.png" alt="image-20230907194527792" style="zoom:50%;" /></p></li><li><p><span>首先创建二分类交叉熵损失对象；对应的函数是pytorch自带的，即</span><code>torch.nn.BCEWithLogitsLoss()</code></p></li><li><p><span>然后传入预测的标签和真实的标签，得到损失结果</span></p><ol start='' ><li><p><span>真实的标签和预测的标签的维度都是</span><code>[16,14]</code><span>，但是预测的标签变量中的元素是概率值，而真实的标签变量的元素不是概率值</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230907194810216.png" referrerpolicy="no-referrer" alt="image-20230907194810216"></p></li><li><p><span>损失值如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230907195106125.png" referrerpolicy="no-referrer" alt="image-20230907195106125"></p></li></ol></li></ol><h4 id='4113视觉文本对齐'><span>4.1.1.3视觉文本对齐</span></h4><blockquote><ol start='' ><li><p><span>是论文中的Visual–Textual Alignment</span></p></li><li><p><span>代码中对应的损失对象为自定义的</span><code>RankingLoss</code><span>类</span></p></li></ol></blockquote><ol start='' ><li><p><span>首先创建</span><code>RankingLoss</code><span>对象；初始化的时候没有什么需要特别指出的操作；</span></p></li><li><p><span>调用</span><code>ranking_loss</code><span>的</span><code>forward</code><span>方法进行损失的计算，传入如下参数：</span></p><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang=""><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang=""><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  # z_image: (batch_size, 512):综合了(即求平均)两张图片的平均池化特征进行线性变换之后的结果</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  # z_text: (batch_size, 512):文本特征的汇总，即开始符这个位置的特征</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  # labels: (batch_size, 14):真实的标签</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  # similarity_function: 'dot' or 'cosine' or 'l2'</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 92px;"></div><div class="CodeMirror-gutters" style="display: none; height: 92px;"></div></div></div></pre><ol start='' ><li><p><span>基于triplet margin loss（</span><font color="blue"><span>后续详细看一下</span></font><span>）计算损失，需要分别给图像和文本计算损失，分别调用</span><code>imposter_img_loss</code><span>和</span><code>imposter_txt_loss</code></p></li><li><p><span>两个函数传入的参数都是一样的：</span></p><ol start='' ><li><p><code>self.imposter_img_loss(z_image, z_text, labels, similarity_function)</code></p></li><li><p><code>self.imposter_txt_loss(z_image, z_text, labels, similarity_function)</code></p></li></ol></li></ol></li></ol><h5 id='41131imposterimgloss函数'><span>4.1.1.3.1imposter_img_loss函数</span></h5><ol start='' ><li><p><span>整个流程：获取批次大小</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><span>遍历这批数据的每一个样本</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><span>针对每个样本，选择一个这个批次中的其他样本的图像作为冒名图像</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><span>然后基于配对图像和冒名图像所对应的疾病标签的差异计算</span><code>margin</code><span>，作为距离的基本量</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><span>然后计算相似度</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><span>然后构建差异相似度加入到损失值中</span></p></li><li><p><span>对于冒名图像的选择：这是单纯通过</span><code>j = i + 1 if i &lt; batch_size - 1 else 0</code><span>选择固定的冒名图像，</span><font color="blue"><span>是可以改进的一个点</span></font><span>。</span></p></li><li><p><span>对于</span><code>margin</code><span>的计算：若两张图像的标签完全一样，则</span><code>margin=0</code><span>，否则依据论文中的公式计算</span><code>margin</code></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908170617973.png" alt="image-20230908170617973" style="zoom: 33%;" /></p><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">if</span> <span class="cm-variable">torch</span>.<span class="cm-property">equal</span>(<span class="cm-variable">labels</span>[<span class="cm-variable">i</span>], <span class="cm-variable">labels</span>[<span class="cm-variable">j</span>]):</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment"># This means the imposter image comes from the same acquisition</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment"># 这里的margin就是所谓的image label difference,对应论文公式(14)中的μ</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment"># 如果两个图像的标签相同，则边界为0</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">margin</span> <span class="cm-operator">=</span> <span class="cm-number">0</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">else</span>:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment"># labels[i].int() | labels[j].int()：按位或，即两个标签中有一个为1，结果就为1</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment"># 然后求和，并使用item()方法将结果转换为Python标量，即获取了求和的结果</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">n</span> <span class="cm-operator">=</span> (<span class="cm-variable">labels</span>[<span class="cm-variable">i</span>].<span class="cm-property">int</span>() <span class="cm-operator">|</span> <span class="cm-variable">labels</span>[<span class="cm-variable">j</span>].<span class="cm-property">int</span>()).<span class="cm-property">sum</span>().<span class="cm-property">item</span>() <span class="cm-comment"># 或运算，再求和;用于对diff进行平均;与论文中的N_L稍有不同</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment"># labels[i].int() ^ labels[j].int()：按位异或，相同为0，不同为1</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">diff</span> <span class="cm-operator">=</span> (<span class="cm-variable">labels</span>[<span class="cm-variable">i</span>].<span class="cm-property">int</span>() <span class="cm-operator">^</span> <span class="cm-variable">labels</span>[<span class="cm-variable">j</span>].<span class="cm-property">int</span>()).<span class="cm-property">sum</span>().<span class="cm-property">item</span>() <span class="cm-comment"># 异或运算，再求和,对应论文公式(14)中的对应元素相减求绝对值再求和</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">margin</span> <span class="cm-operator">=</span> <span class="cm-builtin">max</span>(<span class="cm-number">0.5</span>, <span class="cm-variable">diff</span> <span class="cm-operator">/</span> <span class="cm-variable">n</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 276px;"></div><div class="CodeMirror-gutters" style="display: none; height: 276px;"></div></div></div></pre></li><li><p><span>对于相似度的计算：分别计算配对图像-文本对和冒名图像-文本对的相似度，即</span><code>paired_similarity</code><span>和</span><code>imposter_similarity</code><span>，根据</span><code>similarity_function</code><span>的不同，选择不同的函数进行计算，这里默认使用点积的方式</span></p><ol start='' ><li><p><span>看了代码之后，发现论文中的公式描述有问题，因为实际实现的时候，不管是</span><code>paired_similarity</code><span>还是</span><code>imposter_similarity</code><span>，都是配对的图像和冒名的图像分别与配对的文本进行相似度的计算，</span><u><span>不是下图公式中框选出来的那部分</span></u></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908171728550.png" alt="image-20230908171728550" style="zoom:33%;" /></p></li></ol></li><li><p><span>将相似度计算结果加入到损失中：</span></p><ol start='' ><li><p><span>最终的损失是越小越好，因此加上</span><code>imposter_similarity</code><span>，减去</span><code>paired_similarity</code><span>，这样就是最大化</span><code>paired_similarity</code><span>了；</span></p></li><li><p><span>这里直接用相似度值构建损失，与论文公式(12)不同，公式(12)是用</span><code>1-相似度</code><span>作为距离构建损失的，但是效果应该是一样的</span></p></li></ol><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">diff_similarity</span> <span class="cm-operator">=</span> <span class="cm-variable">imposter_similarity</span> <span class="cm-operator">-</span> <span class="cm-variable">paired_similarity</span> <span class="cm-operator">+</span> <span class="cm-variable">margin</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">if</span> <span class="cm-variable">diff_similarity</span> <span class="cm-operator">&gt;</span> <span class="cm-number">0</span>:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">loss</span> <span class="cm-operator">=</span> <span class="cm-variable">loss</span> <span class="cm-operator">+</span> <span class="cm-variable">diff_similarity</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 69px;"></div><div class="CodeMirror-gutters" style="display: none; height: 69px;"></div></div></div></pre></li></ol><h5 id='41132impostertxtloss函数'><span>4.1.1.3.2imposter_txt_loss函数</span></h5><ol start='' ><li><p><span>大部分内容与</span><code>imposter_img_loss</code><span>一样，唯一的区别在于这里是选择冒名的文本：即计算相似度的时候，使用冒名的文本与配对中的图像计算</span><code>imposter_similarity</code></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908183712399.png" referrerpolicy="no-referrer" alt="image-20230908183712399"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908184149790.png" referrerpolicy="no-referrer" alt="image-20230908184149790"></p></li></ol><h5 id='41133将两个损失加起来'><span>4.1.1.3.3将两个损失加起来</span></h5><ol start='' ><li><p><span>将这两个损失加起来作为视觉-文本对齐的损失，即像文中所说的，双向的对齐</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908185331531.png" referrerpolicy="no-referrer" alt="image-20230908185331531"></p></li></ol><h4 id='4114整合损失'><span>4.1.1.4整合损失</span></h4><ol start='' ><li><p><span>代码中，基本的损失(即Textual–Textual Alignment，交叉熵损失)前面的权重是</span><code>1</code><span>，Visual–Label Alignment和Visual–Textual Alignment前面的权重是固定的</span><code>0.1</code><span>(</span><font color="blue"><span>其实这两个前面的权重也可以改进，即变成动态的</span></font><span>)</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908185734013.png" referrerpolicy="no-referrer" alt="image-20230908185734013"></p></li><li><p><span>公式中是这样的，但其实没有去动态平衡</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230908190943896.png" alt="image-20230908190943896" style="zoom:33%;" /></p></li></ol><h3 id='412损失计算结果'><span>4.1.2损失计算结果</span></h3><p><img src="1-report_generation_for_M2KT.assets/image-20230908192001703.png" referrerpolicy="no-referrer" alt="image-20230908192001703"></p><h2 id='42当前epoch下对模型进行验证'><span>4.2当前epoch下对模型进行验证</span></h2><ol start='' ><li><p><span>首先将模型设置为评估模式，并根据传入的</span><code>mode</code><span>参数选择验证集或者测试集作为数据来源；然后使用</span><code>torch.no_grad()</code><span>方法让模型不去计算梯度，只进行计算；如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230909084756877.png" referrerpolicy="no-referrer" alt="image-20230909084756877"></p></li><li><p><span>接下来，和训练时的计算步骤类似，先设置进度条</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><span>然后使用循环一批一批读取数据</span><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><span>将读取进来的数据传递到GPU上</span></p></li><li><p><span>然后执行</span><code>outputs = self.model(images, mode=&#39;sample&#39;)</code><span>进行模型的计算，这里与训练数据不同的是，只传入了</span><code>images</code><span>，并且</span><code>mode=“sample”</code><span>；</span></p></li><li><p><span>但是和训练的时候也有相同的计算内容：</span></p><ol start='' ><li><p><span>提取图像特征、视觉标签、获取</span><code>memory</code></p></li><li><p><span>然后让视觉标签去注意一下</span><code>memory</code></p></li><li><p><span>然后将提取的图像特征与注意过</span><code>memory</code><span>的视觉标签连接起来，作为最终的图像特征</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230909090637904.png" referrerpolicy="no-referrer" alt="image-20230909090637904"></p></li><li><p><span>和训练的时候不同的地方如下图所示(</span><a href="#anchor7"><span>具体过程见4.2.1使用encoder_decoder计算输出</span></a><span>)：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230909091827106.png" referrerpolicy="no-referrer" alt="image-20230909091827106"></p></li><li><p><span>执行完上图中的</span><code>encoder_decoder</code><span>之后，并将结果返回至</span><code>Trainer</code><span>类的</span><code>_test_step</code><span>方法中，如下图中的</span><code>outputs</code><span>，其中就包含返回过来的</span><code>output</code><span>和</span><code>vis_labels</code><span>。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230911215825087.png" referrerpolicy="no-referrer" alt="image-20230911215825087"></p></li><li><p><span>然后对预测的结果进行解码：</span></p><ol start='' ><li><p><span>下图是解码调用逻辑</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230912100942769.png" referrerpolicy="no-referrer" alt="image-20230912100942769"></p><ol start='2' ><li><p><span>下图是解码输出结果：</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230912101100585.png" referrerpolicy="no-referrer" alt="image-20230912101100585"></p></li><li><p><span>然后使用评价方法进行评估：</span></p><ol start='' ><li><p><span>通过如下语句调用评估方法：</span></p><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">val_met</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">metric_ftns</span>({<span class="cm-variable">i</span>: [<span class="cm-variable">gt</span>] <span class="cm-keyword">for</span> <span class="cm-variable">i</span>, <span class="cm-variable">gt</span> <span class="cm-keyword">in</span> <span class="cm-builtin">enumerate</span>(<span class="cm-variable">val_gts</span>)},</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {<span class="cm-variable">i</span>: [<span class="cm-variable">re</span>] <span class="cm-keyword">for</span> <span class="cm-variable">i</span>, <span class="cm-variable">re</span> <span class="cm-keyword">in</span> <span class="cm-builtin">enumerate</span>(<span class="cm-variable">val_res</span>)})</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 46px;"></div><div class="CodeMirror-gutters" style="display: none; height: 46px;"></div></div></div></pre></li><li><p><span>将会调用</span><code>compute_scores</code><span>方法进行评估，最终得到</span><code>eval_res</code><span>字典，其中存放着每个评估指标的得分(</span><font color="red"><span>需要详细了解一下BLEU指标</span></font><span>)</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230912110049062.png" referrerpolicy="no-referrer" alt="image-20230912110049062"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230912110500046.png" referrerpolicy="no-referrer" alt="image-20230912110500046"></p></li></ol></li><li><p><span>然后执行如下语句将指标的计算结果都存放到</span><code>ilog</code><span>字典中，</span></p><ol start='' ><li><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">ilog</span>.<span class="cm-property">update</span>(<span class="cm-operator">**</span>{<span class="cm-string">f'</span>{<span class="cm-variable">mode</span>}<span class="cm-string">_'</span> <span class="cm-operator">+</span> <span class="cm-variable">k</span>: <span class="cm-variable">v</span> <span class="cm-keyword">for</span> <span class="cm-variable">k</span>, <span class="cm-variable">v</span> <span class="cm-keyword">in</span> <span class="cm-variable">val_met</span>.<span class="cm-property">items</span>()})</span></pre></div></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 23px;"></div><div class="CodeMirror-gutters" style="display: none; height: 23px;"></div></div></div></pre><p><img src="1-report_generation_for_M2KT.assets/image-20230912110606755.png" alt="image-20230912110606755" style="zoom:50%;" /></p></li></ol></li><li><p><span>然后执行</span><code>self._output_generation(val_res, val_gts, val_idxs, epoch, iters, mode)</code><span>：</span></p><ol start='' ><li><p><span>将模型预测结果、真实结果、迭代信息和数据集划分信息保存到一个json文件中，然后返回到</span><code>_train_epoch</code></p><p><img src="1-report_generation_for_M2KT.assets/image-20230912130757954.png" referrerpolicy="no-referrer" alt="image-20230912130757954"></p></li></ol></li></ol><p><span>(</span><a name="anchor7"><span>Anchor7</span></a><span> )</span></p><h3 id='421使用encoderdecoder计算输出'><span>4.2.1使用encoder_decoder计算输出</span></h3><ol start='' ><li><p><span>和训练集一样，也是先调用</span><code>CaptionModel</code><span>的</span><code>forward</code><span>方法(如下图所示)；这里传入了两个关键字参数</span><code>opt=self.args</code><span>和</span><code>mode=&#39;sample&#39;</code><span>，因此接下来将调用</span><code>AttModel</code><span>类的</span><code>_sample</code><span>方法：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230909095716977.png" referrerpolicy="no-referrer" alt="image-20230909095716977"></p></li><li><p><code>_sample</code><span>方法的参数如下：</span></p><ol start='' ><li><p><code>fc_feats</code><span>：对应于</span><code>avg_feats</code><span>，综合了两张图片特征之后的平均池化特征(即对两张图片的平均池化特征求平均)，维度是</span><code>(16,2048)</code></p></li><li><p><code>att_feats</code><span>：对应于</span><code>att_feats</code><span>，提取出来的图像特征(综合了两张图片的特征，且注意过</span><code>memory</code><span>)，维度是</span><code>(16,112,2048)</code></p></li><li><p><code>opt</code><span>：是一开始运行模型的时候使用到的相关参数</span></p></li></ol></li></ol><h4 id='4211sample方法的具体过程'><span>4.2.1.1_sample方法的具体过程</span></h4><blockquote><ol start='' ><li><p><span>首先：获取一些参数</span></p></li><li><p><span>其次：执行</span><code>AttModel</code><span>类的</span><code>self._sample_beam(fc_feats, att_feats, att_masks, opt)</code><span>方法，执行完之后直接在此返回</span></p></li></ol></blockquote><ol start='' ><li><p><span>首先获取一些参数，这些参数的含义及默认值如下图所示：</span></p><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">sample_method</span> <span class="cm-operator">=</span> <span class="cm-builtin">getattr</span>(<span class="cm-variable">opt</span>, <span class="cm-string">'sample_method'</span>, <span class="cm-string">'greedy'</span>)</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">beam_size</span> <span class="cm-operator">=</span> <span class="cm-builtin">getattr</span>(<span class="cm-variable">opt</span>, <span class="cm-string">'beam_size'</span>, <span class="cm-number">1</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">temperature</span> <span class="cm-operator">=</span> <span class="cm-builtin">getattr</span>(<span class="cm-variable">opt</span>, <span class="cm-string">'temperature'</span>, <span class="cm-number">1.0</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">sample_n</span> <span class="cm-operator">=</span> <span class="cm-builtin">int</span>(<span class="cm-builtin">getattr</span>(<span class="cm-variable">opt</span>, <span class="cm-string">'sample_n'</span>, <span class="cm-number">1</span>))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">group_size</span> <span class="cm-operator">=</span> <span class="cm-builtin">getattr</span>(<span class="cm-variable">opt</span>, <span class="cm-string">'group_size'</span>, <span class="cm-number">1</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">output_logsoftmax</span> <span class="cm-operator">=</span> <span class="cm-builtin">getattr</span>(<span class="cm-variable">opt</span>, <span class="cm-string">'output_logsoftmax'</span>, <span class="cm-number">1</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">decoding_constraint</span> <span class="cm-operator">=</span> <span class="cm-builtin">getattr</span>(<span class="cm-variable">opt</span>, <span class="cm-string">'decoding_constraint'</span>, <span class="cm-number">0</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">block_trigrams</span> <span class="cm-operator">=</span> <span class="cm-builtin">getattr</span>(<span class="cm-variable">opt</span>, <span class="cm-string">'block_trigrams'</span>, <span class="cm-number">0</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">remove_bad_endings</span> <span class="cm-operator">=</span> <span class="cm-builtin">getattr</span>(<span class="cm-variable">opt</span>, <span class="cm-string">'remove_bad_endings'</span>, <span class="cm-number">0</span>) <span class="cm-comment"># 参数中没有此项设置，因此默认是0</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 207px;"></div><div class="CodeMirror-gutters" style="display: none; height: 207px;"></div></div></div></pre><p><img src="1-report_generation_for_M2KT.assets/image-20230909153738166.png" referrerpolicy="no-referrer" alt="image-20230909153738166"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230909154111918.png" referrerpolicy="no-referrer" alt="image-20230909154111918"></p></li><li><p><span>剩下有很多代码，但是由于</span><code>if beam_size &gt; 1 and sample_method in [&#39;greedy&#39;, &#39;beam_search&#39;]:</code><span>一定会成立，所以会去执行</span><code>AttModel</code><span>类的</span><code>self._sample_beam(fc_feats, att_feats, att_masks, opt)</code><span>方法，执行完之后直接在此返回。</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230909155529378.png" referrerpolicy="no-referrer" alt="image-20230909155529378"></p></li></ol><h5 id='42111执行attmodel类的samplebeam方法'><span>4.2.1.1.1执行AttModel类的_sample_beam方法</span></h5><blockquote><ol start='' ><li><p><span>首先也是获取一些参数</span></p></li><li><p><span>其次，调用</span><code>TransformerModel</code><span>类的</span><code>_prepare_feature</code><span>方法对</span><code>fc_feats</code><span>和</span><code>att_feats</code><span>进行一些处理(</span><a href="#anchor3"><span>看这里</span></a><span>)，包含：</span></p><ol start='' ><li><p><span>调用</span><code>TransformerModel</code><span>类的</span><code>_prepare_feature_forward</code><span>方法对视觉特征进行embedding操作(本质上是一个线性层+dropout层)，以及生成了一个视觉特征的掩码张量</span></p></li><li><p><span>调用transformer模型的</span><code>EncoderDecoder</code><span>类，但只进行编码得到编码器堆栈的输出(</span><a href="#anchor4"><span>看这里</span></a><span>)</span></p></li></ol></li><li><p><span>接着，初始化</span><code>seq</code><span>及其概率（项目符号列表3），初始化仅含开始符的目标序列（项目符号列表4）</span></p></li><li><p><span>然后基于视觉特征以及初始化的目标序列去预测下一个词（项目符号列表4）</span></p></li><li><p><span>然后基于束搜索给每一张图片生成3个候选解（项目符号列表5、6）</span></p></li><li><p><span>然后基于束搜索结果返回最可靠的序列以及概率（项目符号列表7、8）</span></p></li></ol></blockquote><ol start='' ><li><p><span>首先也是获取了一些参数的值，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230909171149197.png" referrerpolicy="no-referrer" alt="image-20230909171149197"></p></li><li><p><span>然后进入到</span><code>TransformerModel</code><span>类的</span><code>_prepare_feature</code><span>方法对</span><code>fc_feats</code><span>和</span><code>att_feats</code><span>进行一些处理</span></p><ol start='' ><li><p><span>本质上还是调用了</span><code>TransformerModel</code><span>类的</span><code>_prepare_feature_forward</code><span>方法，如下图所示(</span><a id="anchor3"><span>anchor3</span></a><span>)：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230909210401295.png" referrerpolicy="no-referrer" alt="image-20230909210401295"></p></li><li><p><span>传入的变量只有</span><code>att_feats</code><span>和</span><code>att_masks</code><span>，而训练时还传入了</span><code>seq</code><span>，如下图所示；不过与训练时一样的是：</span><code>att_masks=None</code></p><ol start='' ><li><p><span>因为训练时，模型计算同时需要源序列和目标序列，而验证的时候只需要源序列，然后得出</span><code>output</code><span>，再去与真实的目标序列进行对比</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230909210732851.png" referrerpolicy="no-referrer" alt="image-20230909210732851"></p></li><li><p><code>_prepare_feature_forward</code><span>方法的整个过程可以</span><a href="#anchor1"><span>看这里</span></a><span>。这里只说明不同的地方：</span></p><ol start='' ><li><p><span>由于这里是验证，因此没有传入报告文本序列，即目标序列，所以</span><code>seq=None</code><span>，所以就不需要为报告文本生成掩码序列，即</span><code>seq_mask = None</code><span>，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230909213530053.png" referrerpolicy="no-referrer" alt="image-20230909213530053"></p></li><li><p><span>所以，验证的阶段，</span><code>_prepare_feature_forward</code><span>方法只是对视觉特征进行embedding操作(本质上是一个线性层+dropout层)，以及生成了一个视觉特征的掩码张量</span></p></li><li><p><span>最后返回了</span><code>att_feats</code><span>, </span><code>seq</code><span>, </span><code>att_masks</code><span>, </span><code>seq_mask</code><span>，其中</span><code>seq</code><span>和</span><code>seq_mask</code><span>都是</span><code>None</code><span>，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230909213901061.png" referrerpolicy="no-referrer" alt="image-20230909213901061"></p></li></ol></li><li><p><span>在</span><code>TransformerModel</code><span>类的</span><code>_prepare_feature</code><span>方法中，调用完</span><code>_prepare_feature_forward</code><span>方法之后，将调用transformer模型的</span><code>EncoderDecoder</code><span>类，与训练阶段不同的是，在验证阶段，只是调用其中的编码器对注意过</span><code>memory</code><span>的视觉特征进行编码，如下图所示(</span><a id="anchor4"><span>anchor4</span></a><span>)：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230910101022340.png" referrerpolicy="no-referrer" alt="image-20230910101022340"></p><ol start='' ><li><p><span>编码的过程可以</span><a href="#anchor2"><span>看这里</span></a><span>；编码结束得到的就是编码器堆栈的输出，这里记为了</span><code>memory</code><span>，维度是</span><code>[16,112,512]</code><span>，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230910103216570.png" referrerpolicy="no-referrer" alt="image-20230910103216570"></p></li><li><p><span>最后返回结果：</span></p><ol start='' ><li><p><code>fc_feats[..., :0]</code><span>：</span><code>fc_feats</code><span>在</span><code>_prepare_feature</code><span>方法中没有进行任何处理</span></p><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.38281px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># fc_feats[..., :0]表示对数组fc_feats进行切片操作，其中...表示省略其他维度，:表示选择该维度的所有元素，而:0表示选择该维度的前0个元素</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">fc_feats</span>[<span class="cm-operator">...</span>, :<span class="cm-number">0</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">Out</span>[<span class="cm-number">2</span>]: <span class="cm-variable">tensor</span>([], <span class="cm-variable">device</span><span class="cm-operator">=</span><span class="cm-string">'cuda:0'</span>, <span class="cm-variable">size</span><span class="cm-operator">=</span>(<span class="cm-number">16</span>, <span class="cm-number">0</span>)) <span class="cm-comment"># 注意size没变，但是是空的</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 92px;"></div><div class="CodeMirror-gutters" style="display: none; height: 92px;"></div></div></div></pre></li><li><p><code>att_feats[..., :0]</code><span>：经过embedding操作(本质上是一个线性层+dropout层)，因此经过</span><code>_prepare_feature</code><span>方法之后，</span><code>att_feats</code><span>维度从</span><code>[batch_size, 98+14, 2048]</code><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><code>[batch_size, 98+14, 512]</code><mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="1.181ex" role="img" focusable="false" viewBox="0 -511 1000 522" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -0.025ex;"><defs><path id="MJX-17-TEX-N-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="2192" xlink:href="#MJX-17-TEX-N-2192"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container><script type="math/tex">\rightarrow</script><span>并以</span><code>[16, 112, 0]</code><span>返回</span></p><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">att_feats</span>[<span class="cm-operator">...</span>, :<span class="cm-number">0</span>]</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">Out</span>[<span class="cm-number">3</span>]: <span class="cm-variable">tensor</span>([], <span class="cm-variable">device</span><span class="cm-operator">=</span><span class="cm-string">'cuda:0'</span>, <span class="cm-variable">size</span><span class="cm-operator">=</span>(<span class="cm-number">16</span>, <span class="cm-number">112</span>, <span class="cm-number">0</span>)) <span class="cm-comment"># 注意size没变，但是是空的</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 46px;"></div><div class="CodeMirror-gutters" style="display: none; height: 46px;"></div></div></div></pre></li><li><p><code>memory</code><span>：注意过</span><code>memory</code><span>的视觉特征经过编码器堆栈的计算结果，维度是</span><code>[16,112,512]</code></p></li><li><p><code>att_masks</code><span>：视觉特征的掩码张量，全为</span><code>1</code><span>；维度是</span><code>[16,1,112]</code></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230910105723196.png" referrerpolicy="no-referrer" alt="image-20230910105723196"></p></li></ol></li></ol></li><li><p><span>接下来创建</span><code>seq</code><span>和</span><code>seqLogprobs</code><span>变量，应该是用于存放模型在给定视觉特征的情况下生成的报告文本</span></p><ol start='' ><li><p><code>seq</code><span>：由</span><code>seq = fc_feats.new_full((batch_size * sample_n, self.seq_length), self.pad_idx, dtype=torch.long)</code><span>语句创建，关于此语句的解释如下图所示：</span></p><ol start='' ><li><p><span>由此可见，</span><code>sample_n</code><span>的描述“the sample number per image”可以理解为：为每一张图像生成的文本描述的数量</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230910151202035.png" alt="image-20230910151202035" style="zoom:50%;" /></p></li><li><p><code>seqLogprobs</code><span>：由</span><code>seqLogprobs = fc_feats.new_zeros(batch_size * sample_n, self.seq_length, self.vocab_size + 1)</code><span>语句创建，关于此语句的解释如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230910152009277.png" referrerpolicy="no-referrer" alt="image-20230910152009277"></p></li><li><p><span>下图是</span><code>seq</code><span>和</span><code>seqLogprobs</code><span>的创建的结果，</span><code>seq</code><span>的维度是</span><code>[16,60]</code><span>，元素全是填充符；</span><code>seqLogprobs</code><span>的维度是</span><code>[16,60,761]</code><span>，元素都是</span><code>0</code><span>，如下图所示；</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230910152330442.png" referrerpolicy="no-referrer" alt="image-20230910152330442"></p></li></ol></li><li><p><span>然后初始化了一个序列，名为</span><code>it</code><span>，其中的元素都是开始符(即</span><code>0</code><span>)，维度是</span><code>(16,)</code><span>；然后调用</span><code>AttModel</code><span>类的</span><code>get_logprobs_state</code><span>方法(&lt;a </span><a href="#anchor6"><span>&gt;见4.2.1.1.1.1调用</span><code>get_logprobs_state</code><span>方法</span></a><span>)，</span></p><ol start='' ><li><p><span>作用是：在已有视觉特征、视觉特征掩码的情况下，对初始化了的仅有开始符的目标序列进行预测，预测下一个词，最后返回模型的概率输出&amp;初始化的仅有开始符的目标序列</span></p></li></ol></li><li><p><span>然后根据</span><code>beam_size</code><span>的大小将</span><code>p_fc_feats</code><span>、</span><code>p_att_feats</code><span>、</span><code>pp_att_feats</code><span>、</span><code>p_att_masks</code><span>重复</span><code>beam_size</code><span>次</span></p><ol start='' ><li><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="python"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 9.51562px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">p_fc_feats：维度变成是</span>(<span class="cm-number">48</span>,<span class="cm-number">0</span>)<span class="cm-variable">；p_att_feats：维度变成是</span>(<span class="cm-number">48</span>, <span class="cm-number">112</span>, <span class="cm-number">0</span>)<span class="cm-variable">；pp_att_feats：即编码器堆栈的输出memory，维度变成是</span>(<span class="cm-number">48</span>,<span class="cm-number">112</span>,<span class="cm-number">512</span>)<span class="cm-variable">；</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">p_att_masks：维度变成</span>[<span class="cm-number">48</span>,<span class="cm-number">1</span>,<span class="cm-number">112</span>]<span class="cm-variable">，是p_att_feats的掩码张量</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 46px;"></div><div class="CodeMirror-gutters" style="display: none; height: 46px;"></div></div></div></pre></li><li><p><span>目的是进行束搜索，下图是一个简单的解释：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230911152838882.png" alt="image-20230911152838882" style="zoom:50%;" /></p></li></ol></li><li><p><span>接下来就进行束搜索(beam_search)(</span><font color="blue"><span>关于具体的束搜索过程，后面看一下</span></font><span>)，得到下图所示的结果</span></p><ol start='' ><li><p><span>是一个长度为</span><code>16</code><span>的列表，每个列表又包含</span><code>3</code><span>个元素，对应于</span><code>beam_size=3</code><span>；每个元素又是一个字典，包含了序列预测结果、概率值等；</span></p></li><li><p><span>一个批次有</span><code>16</code><span>张图像(综合之后一个批次相当于1张图像)，即利用束搜索给每张图像生成</span><code>3</code><span>个报告文本序列</span></p></li><li><p><span>需要注意的是，每个预测出来的文本序列长度不是固定的</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230911155358733.png" referrerpolicy="no-referrer" alt="image-20230911155358733"></p></li><li><p><span>根据束搜索结果，完善之前创建的</span><code>seq</code><span>以及对应的概率，作为基于视觉特征预测的文本序列以及对应的概率值</span></p><ol start='' ><li><p><span>通过循环为这批数据的每个图像赋值文本序列及概率值</span></p></li><li><p><span>束搜索给每个图像都生成了</span><code>3</code><span>个候选的文本序列预测结果，而第一个具有最高的得分，因此从第一个候选结果中获取预测值，过程如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230911170547498.png" referrerpolicy="no-referrer" alt="image-20230911170547498"></p></li><li><p><span>由于</span><u><span>每个预测的文本序列长度不固定</span></u><span>，因此原先初始化</span><code>seq</code><span>及其概率的时候，设置的默认值</span><code>0</code><span>就起作用了，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230911170733525.png" referrerpolicy="no-referrer" alt="image-20230911170733525"></p><p><img src="1-report_generation_for_M2KT.assets/image-20230911170752059.png" referrerpolicy="no-referrer" alt="image-20230911170752059"></p></li></ol></li><li><p><span>最终的结果如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230911210846299.png" referrerpolicy="no-referrer" alt="image-20230911210846299"></p><ol start='' ><li><p><span>之后逐层返回，最后返回到</span><code>LAMRGModel_v12</code><span>类的</span><code>forward</code><span>方法中，如下图所示</span></p><ol start='' ><li><p><span>返回之后就是下图中的</span><code>output</code><span>，维度是</span><code>[16,60]</code><span>；</span><u><span>返回过来的概率之后就没有利用了</span></u><span>。</span></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230911211437746.png" referrerpolicy="no-referrer" alt="image-20230911211437746"></p></li><li><p><span>调用</span><code>AttModel</code><span>类的</span><code>_sample</code><span>方法返回结果到</span><code>LAMRGModel_v12</code><span>类的</span><code>forward</code><span>方法之后，将基于视觉特征，用束搜索算法生成的文本序列以及视觉标签返回，如下图所示</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230911214633054.png" referrerpolicy="no-referrer" alt="image-20230911214633054"></p></li></ol></li></ol><h6 id='421111调用getlogprobsstate方法'><span>4.2.1.1.1.1调用</span><code>get_logprobs_state</code><span>方法</span></h6><ol start='' ><li><p><span>传入的参数如下图所示(</span><a name="anchor6"></a><span>)：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230911090841293.png" referrerpolicy="no-referrer" alt="image-20230911090841293"></p></li><li><p><span>然后调用</span><code>TransformerModel</code><span>类的</span><code>core</code><span>方法：</span></p><ol start='' ><li><p><span>由</span><code>it</code><span>构建</span><code>ys</code><span>，其实就是将维度变成</span><code>[16,1]</code><span>，元素依旧都是开始符</span><code>0</code></p></li><li><p><span>然后将注意过</span><code>memory</code><span>的视觉特征经过编码器堆栈的计算结果，即编码器堆栈的输出</span><code>memory</code><span>及其掩码张量、刚刚构建的</span><code>ys</code><span>(这里应该是作为目标序列)及其掩码张量传入到encoder_decoder的解码器部分进行解码过程(</span><a href="#anchor5"><span>解码的详细过程</span></a><span>)，不同的地方在于：这里</span><code>tgt</code><span>的维度是</span><code>[16,1]</code><span>，进而导致</span><code>tgt_mask</code><span>等后续张量维度与之前稍许不同。以下是解码的结果：</span></p><ol start='' ><li><p><span>使用</span><code>self.tgt_embed</code><span>对目标序列(报告文本序列)进行embedding操作，从而使</span><code>tgt</code><span>的维度从</span><code>(16,1)</code><span>变为</span><code>(16,1,512)</code></p></li><li><p><span>目标序列的自注意力计算结果的维度是</span><code>[16,1,512]</code></p></li><li><p><span>然后进行编码器堆栈的注意力计算：让目标序列去注意一下视觉特征，得到的结果的维度依旧是</span><code>[16,1,512]</code></p></li><li><p><span>之后是前馈神经网络层</span></p></li><li><p><span>最终解码的结果如下图所示，</span><code>out</code><span>的维度是</span><code>[16,1,512]</code></p></li></ol><p><img src="1-report_generation_for_M2KT.assets/image-20230911110202922.png" referrerpolicy="no-referrer" alt="image-20230911110202922"></p></li><li><p><span>然后返回结果：</span></p><ol start='' ><li><p><code>out[:, -1]</code><span>：相当于根据视觉特征去预测报告文本序列开始符的下一个词是什么；将</span><code>out</code><span>的维度从</span><code>[16,1,512]</code><span>变成</span><code>[16, 512]</code><span>，然后返回，就是降了维度，如下图所示；</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230911115132022.png" alt="image-20230911115132022" style="zoom:50%;" /></p></li><li><p><code>[ys.unsqueeze(0)]</code><span>：目标序列，仅包含开始符；给</span><code>ys</code><span>增加了一个维度，维度从</span><code>[16,1]</code><span>变成</span><code>[1, 16, 1]</code><span>，然后装在一个列表中返回，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230911115244020.png" alt="image-20230911115244020" style="zoom:50%;" /></p></li><li><p><span>返回之后，</span><code>out[:, -1]</code><span>和</span><code>[ys.unsqueeze(0)]</code><span>分别对应</span><code>output, state = self.core(xt, fc_feats, att_feats, p_att_feats, state, att_masks)</code><span>语句中的</span><code>output</code><span>和</span><code>state</code><span>。</span></p></li></ol></li></ol></li><li><p><span>然后对输出进行softmax：</span></p><ol start='' ><li><p><span>首先对</span><code>output</code><span>进行线性变换，维度从</span><code>[16, 512]</code><span>变成</span><code>[16, 761]</code><span>；然后使用</span><code>log_softmax</code><span>转换成概率</span><code>logprobs</code><span>，如下图所示：</span></p><p><img src="1-report_generation_for_M2KT.assets/image-20230911142126015.png" referrerpolicy="no-referrer" alt="image-20230911142126015"></p></li></ol></li><li><p><span>然后返回概率</span><code>logprobs</code><span>以及状态</span><code>state</code><span>；</span></p><ol start='' ><li><p><span>所谓的状态就是当前的目标序列；在此处此时的目标序列就是全部都是开始符</span></p></li></ol></li></ol><h2 id='13当前epoch下对模型进行测试'><span>1.3当前epoch下对模型进行测试</span></h2><ol start='' ><li><p><span>测试的过程与验证类似</span></p></li></ol></div></div>

<script>(function(){function e(e,n,i){document.addEventListener(e,function(e){if(!e.defaultPrevented)for(var t=e.target;t&&t!=this;t=t.parentNode)if(t.matches(n)){!1===i.call(t,e)&&(e.preventDefault(),e.stopPropagation());break}},!1)}var t=document.body.parentElement,i=[],r=null,o=document.body.classList.contains("typora-export-collapse-outline");function a(){return t.scrollTop}e("click",".outline-expander",function(e){var t=this.closest(".outline-item-wrapper").classList;return t.contains("outline-item-open")?t.remove("outline-item-open"):t.add("outline-item-open"),u(),!1}),e("click",".outline-item",function(e){var t=this.querySelector(".outline-label");location.hash="#"+t.getAttribute("href"),o&&((t=this.closest(".outline-item-wrapper").classList).contains("outline-item-open")||t.add("outline-item-open"),d(),t.add("outline-item-active"))});function s(){var e=a();r=null;for(var t=0;t<i.length&&i[t][1]-e<60;t++)r=i[t]}function n(){c=setTimeout(function(){var n;i=[],n=a(),document.querySelector("#write").querySelectorAll("h1, h2, h3, h4, h5, h6").forEach(e=>{var t=e.getAttribute("id");i.push([t,n+e.getBoundingClientRect().y])}),s(),u()},300)}var l,c,d=function(){document.querySelectorAll(".outline-item-active").forEach(e=>e.classList.remove("outline-item-active")),document.querySelectorAll(".outline-item-single.outline-item-open").forEach(e=>e.classList.remove("outline-item-open"))},u=function(){if(r&&(d(),t=document.querySelector('.outline-label[href="#'+(CSS.escape?CSS.escape(r[0]):r[0])+'"]')))if(o){var e=t.closest(".outline-item-open>ul>.outline-item-wrapper");if(e)e.classList.add("outline-item-active");else{for(var t,n=(t=t.closest(".outline-item-wrapper")).parentElement.closest(".outline-item-wrapper");n;)n=(t=n).parentElement.closest(".outline-item-wrapper");t.classList.add("outline-item-active")}}else t.closest(".outline-item-wrapper").classList.add("outline-item-active")};window.addEventListener("scroll",function(e){l&&clearTimeout(l),l=setTimeout(function(){s(),u()},300)});window.addEventListener("resize",function(e){c&&clearTimeout(c),n()}),n()})();</script></body>
</html>